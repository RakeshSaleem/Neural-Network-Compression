{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os, sys, json\n",
    "current_path = os.path.abspath('.')\n",
    "parent_path = os.path.dirname(current_path)\n",
    "sys.path.append(parent_path)\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.data_loader import *\n",
    "from src.utils import *\n",
    "\n",
    "from src.models.simple_cnn import *\n",
    "from src.models.resnet_models import *\n",
    "from src.models.dscnn import *\n",
    "from train_joint import *\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################\n",
    "########## Plot Style Declaration ##########\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "# plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.rcParams['font.family'] = 'times new roman'\n",
    "# plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "# plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "##################################\n",
    "########## End of Setup ##########\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import tensorflow_addons as tfa\n",
    "# from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgClass():\n",
    "    def __init__(self):\n",
    "        super(ArgClass, self).__init__()\n",
    "\n",
    "args = ArgClass()\n",
    "args.dataset=\"cifar10\"\n",
    "args.model_arch = \"cnn\"\n",
    "args.batch_size=128\n",
    "args.test_batch_size=1000\n",
    "args.percent=[0.8, 0.92, 0.991, 0.93]\n",
    "args.alpha=5e-4\n",
    "args.rho=1e-2\n",
    "args.l1=False\n",
    "args.l2=False\n",
    "args.num_pre_epochs=3\n",
    "args.num_epochs=10\n",
    "args.num_re_epochs=3\n",
    "args.lr=1e-3\n",
    "args.adam_epsilon=1e-8\n",
    "args.no_cuda=False\n",
    "args.seed=1\n",
    "args.save_model=False\n",
    "args.shuffle=True\n",
    "\n",
    "args.optimizer_name = 'adam'\n",
    "args.lr_mode = 'multistep'\n",
    "args.lr_decay = 0.1\n",
    "args.lr_decay_epoch = '20,40'\n",
    "args.target_lr = 1e-8\n",
    "args.warmup_epochs = 0\n",
    "args.warmup_lr = 1e-8\n",
    "args.warmup_mode = 'linear'\n",
    "args.momentum = 0.9\n",
    "args.wd = 0.0001\n",
    "args.gamma_wd_mult = 1.0\n",
    "args.beta_wd_mult = 1.0\n",
    "args.bias_wd_mult = 1.0\n",
    "args.grad_clip = None\n",
    "args.label_smoothing = False\n",
    "\n",
    "\n",
    "args.test_fold_l = '[10]'\n",
    "args.use_one_task = 'false'\n",
    "args.exp_setup = ''\n",
    "args.subject_idx = None\n",
    "args.pretrained=False\n",
    "args.best_acc = 200.0\n",
    "args.mixup = False\n",
    "args.mixup_alpha = 1.0\n",
    "args.mixup_epoch_tail = 10\n",
    "args.session = 1\n",
    "args.test_vote = None\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "tf.random.set_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# Setting seed for reproducibiltiy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MicroNet-AD-K\n",
    "init_block_channel = 168\n",
    "init_block_stride = (1,1)\n",
    "channels = [[192],[192],[192],[192],[192]]\n",
    "# channels = [[276],[276],[276],[276],[276]]\n",
    "strides = [2, 1, 1, 2, 2]\n",
    "\n",
    "def get_pool_size(strides, config):\n",
    "    pool_size = None\n",
    "    for stride in strides:\n",
    "        if stride > 1:\n",
    "            if pool_size is None:\n",
    "                pool_size=[np.ceil(config[\"seq\"]/2),np.ceil(config[\"features\"]/2)]\n",
    "            else:\n",
    "                pool_size = [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n",
    "    # return pool_size\n",
    "    return [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.backend.image_data_format())\n",
    "# force channels-first ordering\n",
    "# tf.keras.backend.set_image_data_format('channels_first')\n",
    "# print(tf.keras.backend.image_data_format())\n",
    "# bn_axis=1\n",
    "# channel_ordering='channels_first'\n",
    "# force channels-last ordering\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "print(tf.keras.backend.image_data_format())\n",
    "bn_axis=-1\n",
    "channel_ordering='channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import cifar10\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load data\n",
    "    (trainX, trainY), (testX, testY) = keras.datasets.cifar10.load_data()\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def scale(train, test):\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "\n",
    "    # normalize\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    \n",
    "    mean_rgb = (0.4914, 0.4822, 0.4465)\n",
    "    std_rgb = (0.24703233,0.24348505,0.26158768)\n",
    "    for i in range(3):\n",
    "        train_norm[:,:,:,i] = (train_norm[:,:,:,i]-mean_rgb[i])/std_rgb[i]\n",
    "        test_norm[:,:,:,i] = (test_norm[:,:,:,i]-mean_rgb[i])/std_rgb[i]\n",
    "    \n",
    "    return train_norm, test_norm\n",
    "\n",
    "train_X, train_y, test_X, test_y = load_dataset()\n",
    "\n",
    "train_X, test_X = scale(train_X, test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import tensorflow_addons as tfa\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model3 = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"],\n",
    "                       kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing (Resizing)          (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_flip (RandomFlip)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_zoom (RandomZoom)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 168)       4536      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 168)       672       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 168)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 16, 168)       1512      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 168)       672       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 168)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 192)       32256     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 16, 16, 192)       1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 192)       36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 16, 16, 192)       1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 192)       36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 8, 8, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 4, 4, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 192)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7690      \n",
      "=================================================================\n",
      "Total params: 208,618\n",
      "Trainable params: 204,490\n",
      "Non-trainable params: 4,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.6016 - sparse_categorical_accuracy: 0.4132 - val_loss: 1.3994 - val_sparse_categorical_accuracy: 0.5097\n",
      "Epoch 2/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.2106 - sparse_categorical_accuracy: 0.5649 - val_loss: 1.0899 - val_sparse_categorical_accuracy: 0.6134\n",
      "Epoch 3/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0276 - sparse_categorical_accuracy: 0.6337 - val_loss: 1.0377 - val_sparse_categorical_accuracy: 0.6370\n",
      "Epoch 4/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9125 - sparse_categorical_accuracy: 0.6787 - val_loss: 0.8635 - val_sparse_categorical_accuracy: 0.6956\n",
      "Epoch 5/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.8258 - sparse_categorical_accuracy: 0.7089 - val_loss: 0.8090 - val_sparse_categorical_accuracy: 0.7158\n",
      "Epoch 6/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.7690 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.7375 - val_sparse_categorical_accuracy: 0.7416\n",
      "Epoch 7/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.7121 - sparse_categorical_accuracy: 0.7511 - val_loss: 0.7267 - val_sparse_categorical_accuracy: 0.7457\n",
      "Epoch 8/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.6802 - sparse_categorical_accuracy: 0.7627 - val_loss: 0.7021 - val_sparse_categorical_accuracy: 0.7584\n",
      "Epoch 9/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 10/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.6095 - sparse_categorical_accuracy: 0.7896 - val_loss: 0.6822 - val_sparse_categorical_accuracy: 0.7665\n",
      "Epoch 11/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.7780\n",
      "Epoch 12/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.7808\n",
      "Epoch 13/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.7801\n",
      "Epoch 14/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.5248 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.7864\n",
      "Epoch 15/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.5157 - sparse_categorical_accuracy: 0.8195 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.7979\n",
      "Epoch 16/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.4915 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.7817\n",
      "Epoch 17/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.4806 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 18/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8404 - val_loss: 0.5716 - val_sparse_categorical_accuracy: 0.8107\n",
      "Epoch 19/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.4559 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.5612 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 20/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.4774 - val_sparse_categorical_accuracy: 0.8371\n",
      "Epoch 21/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8475 - val_loss: 0.5674 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 22/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8494 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.8022\n",
      "Epoch 23/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.4239 - sparse_categorical_accuracy: 0.8536 - val_loss: 0.6070 - val_sparse_categorical_accuracy: 0.8033\n",
      "Epoch 24/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.8013\n",
      "Epoch 25/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.4087 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.8098\n",
      "Epoch 26/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.4006 - sparse_categorical_accuracy: 0.8613 - val_loss: 0.5559 - val_sparse_categorical_accuracy: 0.8192\n",
      "Epoch 27/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3953 - sparse_categorical_accuracy: 0.8630 - val_loss: 0.5054 - val_sparse_categorical_accuracy: 0.8338\n",
      "Epoch 28/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3835 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.4958 - val_sparse_categorical_accuracy: 0.8373\n",
      "Epoch 29/80\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.3818 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.5805 - val_sparse_categorical_accuracy: 0.8102\n",
      "Epoch 30/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3816 - sparse_categorical_accuracy: 0.8681 - val_loss: 0.5060 - val_sparse_categorical_accuracy: 0.8323\n",
      "Epoch 31/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3704 - sparse_categorical_accuracy: 0.8705 - val_loss: 0.5133 - val_sparse_categorical_accuracy: 0.8319\n",
      "Epoch 32/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.4993 - val_sparse_categorical_accuracy: 0.8357\n",
      "Epoch 33/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.8348\n",
      "Epoch 34/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3691 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.4851 - val_sparse_categorical_accuracy: 0.8402\n",
      "Epoch 35/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3587 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.4480 - val_sparse_categorical_accuracy: 0.8504\n",
      "Epoch 36/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3591 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.4763 - val_sparse_categorical_accuracy: 0.8447\n",
      "Epoch 37/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3549 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.4584 - val_sparse_categorical_accuracy: 0.8482\n",
      "Epoch 38/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3560 - sparse_categorical_accuracy: 0.8778 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.8307\n",
      "Epoch 39/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.8787 - val_loss: 0.5032 - val_sparse_categorical_accuracy: 0.8403\n",
      "Epoch 40/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3427 - sparse_categorical_accuracy: 0.8798 - val_loss: 0.5335 - val_sparse_categorical_accuracy: 0.8307\n",
      "Epoch 41/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.8464\n",
      "Epoch 42/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3433 - sparse_categorical_accuracy: 0.8800 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.8360\n",
      "Epoch 43/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3381 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.4876 - val_sparse_categorical_accuracy: 0.8405\n",
      "Epoch 44/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3363 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.4636 - val_sparse_categorical_accuracy: 0.8504\n",
      "Epoch 45/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3346 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.5118 - val_sparse_categorical_accuracy: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3299 - sparse_categorical_accuracy: 0.8846 - val_loss: 0.4954 - val_sparse_categorical_accuracy: 0.8369\n",
      "Epoch 47/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8830 - val_loss: 0.4734 - val_sparse_categorical_accuracy: 0.8430\n",
      "Epoch 48/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8619\n",
      "Epoch 49/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3247 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8506\n",
      "Epoch 50/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3238 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.5073 - val_sparse_categorical_accuracy: 0.8361\n",
      "Epoch 51/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3272 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.8478\n",
      "Epoch 52/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3205 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6095 - val_sparse_categorical_accuracy: 0.8085\n",
      "Epoch 53/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3211 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.4801 - val_sparse_categorical_accuracy: 0.8472\n",
      "Epoch 54/80\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.3196 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.5312 - val_sparse_categorical_accuracy: 0.8273\n",
      "Epoch 55/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3208 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.4898 - val_sparse_categorical_accuracy: 0.8419\n",
      "Epoch 56/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3112 - sparse_categorical_accuracy: 0.8915 - val_loss: 0.4958 - val_sparse_categorical_accuracy: 0.8385\n",
      "Epoch 57/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3150 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.4975 - val_sparse_categorical_accuracy: 0.8415\n",
      "Epoch 58/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3119 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.5085 - val_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 59/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3142 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8485\n",
      "Epoch 60/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3075 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8508\n",
      "Epoch 61/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8521\n",
      "Epoch 62/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3054 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.8512\n",
      "Epoch 63/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3098 - sparse_categorical_accuracy: 0.8911 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.8343\n",
      "Epoch 64/80\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.3099 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.4969 - val_sparse_categorical_accuracy: 0.8379\n",
      "Epoch 65/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3026 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.4655 - val_sparse_categorical_accuracy: 0.8518\n",
      "Epoch 66/80\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.3057 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.5003 - val_sparse_categorical_accuracy: 0.8450\n",
      "Epoch 67/80\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.3000 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.4474 - val_sparse_categorical_accuracy: 0.8577\n",
      "Epoch 68/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3069 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.4241 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 69/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3033 - sparse_categorical_accuracy: 0.8954 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.8479\n",
      "Epoch 70/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.8606\n",
      "Epoch 71/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2978 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8462\n",
      "Epoch 72/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8516\n",
      "Epoch 73/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.4426 - val_sparse_categorical_accuracy: 0.8530\n",
      "Epoch 74/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.8975 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8461\n",
      "Epoch 75/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.3046 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.4635 - val_sparse_categorical_accuracy: 0.8483\n",
      "Epoch 76/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.4118 - val_sparse_categorical_accuracy: 0.8663\n",
      "Epoch 77/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2958 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.8439\n",
      "Epoch 78/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.4548 - val_sparse_categorical_accuracy: 0.8532\n",
      "Epoch 79/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.4299 - val_sparse_categorical_accuracy: 0.8566\n",
      "Epoch 80/80\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.2930 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=128,\n",
    "      epochs=80,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9255 - val_loss: 0.3896 - val_sparse_categorical_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.3779 - val_sparse_categorical_accuracy: 0.8751\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1807 - sparse_categorical_accuracy: 0.9425 - val_loss: 0.3760 - val_sparse_categorical_accuracy: 0.8752\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.3409 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.3426 - val_sparse_categorical_accuracy: 0.8847\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9478 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8804\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1640 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3511 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1649 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.8847\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.3716 - val_sparse_categorical_accuracy: 0.8751\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.3727 - val_sparse_categorical_accuracy: 0.8765\n",
      "Epoch 12/20\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.3449 - val_sparse_categorical_accuracy: 0.8830\n",
      "Epoch 13/20\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1541 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.3898 - val_sparse_categorical_accuracy: 0.8698\n",
      "Epoch 14/20\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.3811 - val_sparse_categorical_accuracy: 0.8715\n",
      "Epoch 15/20\n",
      "391/391 [==============================] - 10s 24ms/step - loss: 0.1510 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.3713 - val_sparse_categorical_accuracy: 0.8789\n",
      "Epoch 16/20\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9550 - val_loss: 0.3694 - val_sparse_categorical_accuracy: 0.8780\n",
      "Epoch 17/20\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.8859\n",
      "Epoch 18/20\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1497 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.3794 - val_sparse_categorical_accuracy: 0.8753\n",
      "Epoch 19/20\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1497 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.3732 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9578 - val_loss: 0.3327 - val_sparse_categorical_accuracy: 0.8890\n"
     ]
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=128,\n",
    "      epochs=20,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import tensorflow_addons as tfa\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "mmt=0.1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model3 = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"],\n",
    "                       kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.5056 - sparse_categorical_accuracy: 0.4504 - val_loss: 1.1011 - val_sparse_categorical_accuracy: 0.6010\n",
      "Epoch 2/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1024 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.0331 - val_sparse_categorical_accuracy: 0.6401\n",
      "Epoch 3/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.9415 - sparse_categorical_accuracy: 0.6687 - val_loss: 1.0602 - val_sparse_categorical_accuracy: 0.6418\n",
      "Epoch 4/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8490 - sparse_categorical_accuracy: 0.7007 - val_loss: 0.8311 - val_sparse_categorical_accuracy: 0.7093\n",
      "Epoch 5/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7797 - sparse_categorical_accuracy: 0.7257 - val_loss: 0.7945 - val_sparse_categorical_accuracy: 0.7250\n",
      "Epoch 6/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7280 - sparse_categorical_accuracy: 0.7461 - val_loss: 0.7975 - val_sparse_categorical_accuracy: 0.7254\n",
      "Epoch 7/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.7585\n",
      "Epoch 8/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6692 - sparse_categorical_accuracy: 0.7697 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.7671\n",
      "Epoch 9/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.7758 - val_loss: 0.7907 - val_sparse_categorical_accuracy: 0.7395\n",
      "Epoch 10/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.6630 - val_sparse_categorical_accuracy: 0.7731\n",
      "Epoch 11/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6161 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.7423\n",
      "Epoch 12/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6099 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 13/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5999 - sparse_categorical_accuracy: 0.7922 - val_loss: 0.6313 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 14/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6010 - sparse_categorical_accuracy: 0.7935 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.7806\n",
      "Epoch 15/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5946 - sparse_categorical_accuracy: 0.7948 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.7742\n",
      "Epoch 16/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.7663\n",
      "Epoch 17/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.6487 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 18/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5811 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.7905\n",
      "Epoch 19/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5807 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 20/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.6616 - val_sparse_categorical_accuracy: 0.7732\n",
      "Epoch 21/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.7774\n",
      "Epoch 22/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.7981\n",
      "Epoch 23/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.7773\n",
      "Epoch 24/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5663 - sparse_categorical_accuracy: 0.8032 - val_loss: 0.5552 - val_sparse_categorical_accuracy: 0.8123\n",
      "Epoch 25/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.7513 - val_sparse_categorical_accuracy: 0.7539\n",
      "Epoch 26/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.7271 - val_sparse_categorical_accuracy: 0.7563\n",
      "Epoch 27/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.7457 - val_sparse_categorical_accuracy: 0.7587\n",
      "Epoch 28/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.7846\n",
      "Epoch 29/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.6396 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 30/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.5503 - val_sparse_categorical_accuracy: 0.8153\n",
      "Epoch 31/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.8028\n",
      "Epoch 32/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.6188 - val_sparse_categorical_accuracy: 0.7947\n",
      "Epoch 33/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.6130 - val_sparse_categorical_accuracy: 0.7947\n",
      "Epoch 34/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5566 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.5801 - val_sparse_categorical_accuracy: 0.8013\n",
      "Epoch 35/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.5459 - val_sparse_categorical_accuracy: 0.8098\n",
      "Epoch 36/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.6118 - val_sparse_categorical_accuracy: 0.7906\n",
      "Epoch 37/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5558 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 38/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.5695 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 39/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.6172 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 40/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.7782\n",
      "Epoch 41/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5491 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.7940\n",
      "Epoch 42/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.7804\n",
      "Epoch 43/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5509 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.7719\n",
      "Epoch 44/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.7966 - val_sparse_categorical_accuracy: 0.7475\n",
      "Epoch 45/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.9278 - val_sparse_categorical_accuracy: 0.7187\n",
      "Epoch 46/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.7838\n",
      "Epoch 47/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5466 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.7838\n",
      "Epoch 48/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 49/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.6384 - val_sparse_categorical_accuracy: 0.7830\n",
      "Epoch 50/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5533 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.7183 - val_sparse_categorical_accuracy: 0.7660\n",
      "Epoch 51/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.6530 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 52/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5484 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.5525 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 53/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.7916\n",
      "Epoch 54/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5476 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.5565 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 55/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.5974 - val_sparse_categorical_accuracy: 0.7924\n",
      "Epoch 56/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.6093 - val_sparse_categorical_accuracy: 0.7940\n",
      "Epoch 57/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.7689\n",
      "Epoch 58/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.7787\n",
      "Epoch 59/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5552 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 60/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5462 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 61/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5518 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.8185\n",
      "Epoch 62/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 63/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.7167 - val_sparse_categorical_accuracy: 0.7625\n",
      "Epoch 64/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.7693\n",
      "Epoch 65/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.8005\n",
      "Epoch 66/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.7785\n",
      "Epoch 67/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.5931 - val_sparse_categorical_accuracy: 0.7976\n",
      "Epoch 68/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.8033\n",
      "Epoch 69/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.8186\n",
      "Epoch 70/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5387 - val_sparse_categorical_accuracy: 0.8158\n",
      "Epoch 71/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5471 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.6158 - val_sparse_categorical_accuracy: 0.7928\n",
      "Epoch 72/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.5415 - val_sparse_categorical_accuracy: 0.8151\n",
      "Epoch 73/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.5864 - val_sparse_categorical_accuracy: 0.8017\n",
      "Epoch 74/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.7730\n",
      "Epoch 75/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.7598\n",
      "Epoch 76/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5512 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 77/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5823 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 78/80\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.7597\n",
      "Epoch 79/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.7685\n",
      "Epoch 80/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.8048\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=80,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.4600 - sparse_categorical_accuracy: 0.8431 - val_loss: 0.4872 - val_sparse_categorical_accuracy: 0.8414\n"
     ]
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=1,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.3658 - sparse_categorical_accuracy: 0.8807 - val_loss: 0.4433 - val_sparse_categorical_accuracy: 0.8494\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3805 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.8455\n"
     ]
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=2,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import tensorflow_addons as tfa\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "mmt=0.2\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model3 = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"],\n",
    "                       kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.4994 - sparse_categorical_accuracy: 0.4533 - val_loss: 1.1115 - val_sparse_categorical_accuracy: 0.5963\n",
      "Epoch 2/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.0945 - sparse_categorical_accuracy: 0.6084 - val_loss: 1.0083 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 3/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.9328 - sparse_categorical_accuracy: 0.6712 - val_loss: 1.0028 - val_sparse_categorical_accuracy: 0.6516\n",
      "Epoch 4/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8436 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.8492 - val_sparse_categorical_accuracy: 0.7128\n",
      "Epoch 5/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7817 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.7566 - val_sparse_categorical_accuracy: 0.7405\n",
      "Epoch 6/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7332 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.8227 - val_sparse_categorical_accuracy: 0.7276\n",
      "Epoch 7/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 8/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6693 - sparse_categorical_accuracy: 0.7697 - val_loss: 0.6173 - val_sparse_categorical_accuracy: 0.7889\n",
      "Epoch 9/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6517 - sparse_categorical_accuracy: 0.7751 - val_loss: 0.7991 - val_sparse_categorical_accuracy: 0.7348\n",
      "Epoch 10/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6379 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.6380 - val_sparse_categorical_accuracy: 0.7803\n",
      "Epoch 11/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6197 - sparse_categorical_accuracy: 0.7867 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.7505\n",
      "Epoch 12/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6103 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.7735\n",
      "Epoch 13/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6055 - sparse_categorical_accuracy: 0.7908 - val_loss: 0.6288 - val_sparse_categorical_accuracy: 0.7843\n",
      "Epoch 14/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5904 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.7769\n",
      "Epoch 15/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5954 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.6255 - val_sparse_categorical_accuracy: 0.7849\n",
      "Epoch 16/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 17/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.7934\n",
      "Epoch 18/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5832 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.6273 - val_sparse_categorical_accuracy: 0.7874\n",
      "Epoch 19/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.8036\n",
      "Epoch 20/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5773 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.7826\n",
      "Epoch 21/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7655\n",
      "Epoch 22/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.7995\n",
      "Epoch 23/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 24/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.7986\n",
      "Epoch 25/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5651 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.7628\n",
      "Epoch 26/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5616 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.6205 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 27/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.7690\n",
      "Epoch 28/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.5806 - val_sparse_categorical_accuracy: 0.8050\n",
      "Epoch 29/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.6348 - val_sparse_categorical_accuracy: 0.7834\n",
      "Epoch 30/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.5805 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 31/40\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5547 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.5428 - val_sparse_categorical_accuracy: 0.8202\n",
      "Epoch 32/40\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.7383 - val_sparse_categorical_accuracy: 0.7616\n",
      "Epoch 33/40\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5478 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.5653 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 34/40\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.8018\n",
      "Epoch 35/40\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 36/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5481 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.8001\n",
      "Epoch 37/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5439 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.7180 - val_sparse_categorical_accuracy: 0.7681\n",
      "Epoch 38/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.7973\n",
      "Epoch 39/40\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.7975\n",
      "Epoch 40/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5492 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.6051 - val_sparse_categorical_accuracy: 0.8062\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=80,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4562 - sparse_categorical_accuracy: 0.8431 - val_loss: 0.4600 - val_sparse_categorical_accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=1,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3570 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.4239 - val_sparse_categorical_accuracy: 0.8545\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.8815 - val_loss: 0.4363 - val_sparse_categorical_accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=2,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import tensorflow_addons as tfa\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "mmt=0.2\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model4 = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"],\n",
    "                       kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.5228 - sparse_categorical_accuracy: 0.4446 - val_loss: 1.1274 - val_sparse_categorical_accuracy: 0.5926\n",
      "Epoch 2/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1228 - sparse_categorical_accuracy: 0.5978 - val_loss: 1.0315 - val_sparse_categorical_accuracy: 0.6389\n",
      "Epoch 3/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.9646 - sparse_categorical_accuracy: 0.6554 - val_loss: 1.0055 - val_sparse_categorical_accuracy: 0.6554\n",
      "Epoch 4/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8664 - sparse_categorical_accuracy: 0.6950 - val_loss: 0.8279 - val_sparse_categorical_accuracy: 0.7123\n",
      "Epoch 5/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.8033 - sparse_categorical_accuracy: 0.7200 - val_loss: 0.8014 - val_sparse_categorical_accuracy: 0.7293\n",
      "Epoch 6/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7469 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.7429 - val_sparse_categorical_accuracy: 0.7443\n",
      "Epoch 7/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.7089 - sparse_categorical_accuracy: 0.7529 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 8/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.7608 - val_sparse_categorical_accuracy: 0.7469\n",
      "Epoch 9/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6619 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.7596 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 10/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6423 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.6424 - val_sparse_categorical_accuracy: 0.7766\n",
      "Epoch 11/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6289 - sparse_categorical_accuracy: 0.7828 - val_loss: 0.8224 - val_sparse_categorical_accuracy: 0.7295\n",
      "Epoch 12/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6132 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.6144 - val_sparse_categorical_accuracy: 0.7925\n",
      "Epoch 13/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6047 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 14/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5978 - sparse_categorical_accuracy: 0.7929 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 15/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.6733 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 16/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.7685 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 17/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5806 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 18/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.7999 - val_loss: 0.6572 - val_sparse_categorical_accuracy: 0.7824\n",
      "Epoch 19/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5808 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 20/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5745 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.7629 - val_sparse_categorical_accuracy: 0.7532\n",
      "Epoch 21/80\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.5704 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.7834\n",
      "Epoch 22/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.7848\n",
      "Epoch 23/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5707 - sparse_categorical_accuracy: 0.8035 - val_loss: 0.6080 - val_sparse_categorical_accuracy: 0.7886\n",
      "Epoch 24/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.5924 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 25/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5609 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.7774\n",
      "Epoch 26/80\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.7797\n",
      "Epoch 27/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.7090 - val_sparse_categorical_accuracy: 0.7630\n",
      "Epoch 28/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.7933\n",
      "Epoch 29/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5593 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.6300 - val_sparse_categorical_accuracy: 0.7903\n",
      "Epoch 30/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5616 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.8052\n",
      "Epoch 31/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.5815 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 32/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5566 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.7730\n",
      "Epoch 33/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5567 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.5763 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 34/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5557 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.5542 - val_sparse_categorical_accuracy: 0.8121\n",
      "Epoch 35/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.5317 - val_sparse_categorical_accuracy: 0.8151\n",
      "Epoch 36/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5523 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.8070\n",
      "Epoch 37/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.6372 - val_sparse_categorical_accuracy: 0.7802\n",
      "Epoch 38/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.8093\n",
      "Epoch 39/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.5837 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 40/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5512 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.8123\n",
      "Epoch 41/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.7795\n",
      "Epoch 42/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.7983\n",
      "Epoch 43/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.7872\n",
      "Epoch 44/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5538 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.7771\n",
      "Epoch 45/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5613 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.7715\n",
      "Epoch 46/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.5771 - val_sparse_categorical_accuracy: 0.8075\n",
      "Epoch 47/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5547 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.5997 - val_sparse_categorical_accuracy: 0.7964\n",
      "Epoch 48/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 49/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.8163\n",
      "Epoch 50/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.7697\n",
      "Epoch 51/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.7810\n",
      "Epoch 52/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.5726 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 53/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.6060 - val_sparse_categorical_accuracy: 0.7961\n",
      "Epoch 54/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.5261 - val_sparse_categorical_accuracy: 0.8199\n",
      "Epoch 55/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5552 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.6794 - val_sparse_categorical_accuracy: 0.7660\n",
      "Epoch 56/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.8081\n",
      "Epoch 57/80\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5569 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.7144 - val_sparse_categorical_accuracy: 0.7614\n",
      "Epoch 58/80\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 59/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.5502 - val_sparse_categorical_accuracy: 0.8088\n",
      "Epoch 60/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5546 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.8144\n",
      "Epoch 61/80\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5581 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 62/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.8151\n",
      "Epoch 63/80\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5547 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.7987\n",
      "Epoch 64/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.6809 - val_sparse_categorical_accuracy: 0.7761\n",
      "Epoch 65/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5517 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.8151\n",
      "Epoch 66/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.5882 - val_sparse_categorical_accuracy: 0.7996\n",
      "Epoch 67/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.7773\n",
      "Epoch 68/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.7836\n",
      "Epoch 69/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5575 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.5336 - val_sparse_categorical_accuracy: 0.8132\n",
      "Epoch 70/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.5437 - val_sparse_categorical_accuracy: 0.8082\n",
      "Epoch 71/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5557 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.7836\n",
      "Epoch 72/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.8222\n",
      "Epoch 73/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5614 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.6108 - val_sparse_categorical_accuracy: 0.7927\n",
      "Epoch 74/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.8284 - val_sparse_categorical_accuracy: 0.7317\n",
      "Epoch 75/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.7781\n",
      "Epoch 76/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.7801\n",
      "Epoch 77/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7994\n",
      "Epoch 78/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 79/80\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5646 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.7883\n",
      "Epoch 80/80\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.6181 - val_sparse_categorical_accuracy: 0.7976\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=80,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4712 - sparse_categorical_accuracy: 0.8377 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "model4.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model4.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=1,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3801 - sparse_categorical_accuracy: 0.8771 - val_loss: 0.4219 - val_sparse_categorical_accuracy: 0.8552\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.3883 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.4737 - val_sparse_categorical_accuracy: 0.8367\n"
     ]
    }
   ],
   "source": [
    "model4.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model4.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=2,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MicroNet-AD-K\n",
    "init_block_channel = 168\n",
    "init_block_stride = (1,1)\n",
    "# channels = [[192],[192],[192],[192],[192]]\n",
    "channels = [[276],[276],[276],[276],[276]]\n",
    "strides = [2, 1, 1, 2, 2]\n",
    "\n",
    "def get_pool_size(strides, config):\n",
    "    pool_size = None\n",
    "    for stride in strides:\n",
    "        if stride > 1:\n",
    "            if pool_size is None:\n",
    "                pool_size=[np.ceil(config[\"seq\"]/2),np.ceil(config[\"features\"]/2)]\n",
    "            else:\n",
    "                pool_size = [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n",
    "    # return pool_size\n",
    "    return [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.4713 - sparse_categorical_accuracy: 0.4665 - val_loss: 1.0642 - val_sparse_categorical_accuracy: 0.6220\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 1.0451 - sparse_categorical_accuracy: 0.6319 - val_loss: 0.9381 - val_sparse_categorical_accuracy: 0.6779\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8882 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.9478 - val_sparse_categorical_accuracy: 0.6703\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7948 - sparse_categorical_accuracy: 0.7211 - val_loss: 0.8299 - val_sparse_categorical_accuracy: 0.7199\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7273 - sparse_categorical_accuracy: 0.7457 - val_loss: 0.7617 - val_sparse_categorical_accuracy: 0.7385\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6790 - sparse_categorical_accuracy: 0.7652 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.7650\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.6425 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.6208 - val_sparse_categorical_accuracy: 0.7866\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6260 - sparse_categorical_accuracy: 0.7827 - val_loss: 0.6390 - val_sparse_categorical_accuracy: 0.7780\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.7907 - val_loss: 0.7201 - val_sparse_categorical_accuracy: 0.7565\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.7635\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5750 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.7570\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.7829\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5524 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.5965 - val_sparse_categorical_accuracy: 0.7958\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.7902\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.7749\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.5891 - val_sparse_categorical_accuracy: 0.8036\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.8017\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.5411 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.5717 - val_sparse_categorical_accuracy: 0.8065\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5322 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.7163 - val_sparse_categorical_accuracy: 0.7585\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.5855 - val_sparse_categorical_accuracy: 0.8076\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.5314 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.5829 - val_sparse_categorical_accuracy: 0.8009\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5292 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.5801 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.5275 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.7743\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5265 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.7581\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5268 - sparse_categorical_accuracy: 0.8171 - val_loss: 0.7266 - val_sparse_categorical_accuracy: 0.7594\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5288 - sparse_categorical_accuracy: 0.8161 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7942\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5253 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.6062 - val_sparse_categorical_accuracy: 0.7951\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5276 - sparse_categorical_accuracy: 0.8190 - val_loss: 0.5596 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.8059\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5252 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.6992 - val_sparse_categorical_accuracy: 0.7689\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5282 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.5415 - val_sparse_categorical_accuracy: 0.8192\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5285 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.5453 - val_sparse_categorical_accuracy: 0.8163\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5270 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.5403 - val_sparse_categorical_accuracy: 0.8158\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5223 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.5425 - val_sparse_categorical_accuracy: 0.8164\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5240 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.7622\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5226 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.5594 - val_sparse_categorical_accuracy: 0.8149\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5274 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.5316 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5198 - sparse_categorical_accuracy: 0.8217 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5230 - sparse_categorical_accuracy: 0.8190 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.8172\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5214 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.7628\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5214 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.7267 - val_sparse_categorical_accuracy: 0.7554\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5246 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7824\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.7749\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5233 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.7900\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5157 - sparse_categorical_accuracy: 0.8241 - val_loss: 0.5763 - val_sparse_categorical_accuracy: 0.8092\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.5242 - sparse_categorical_accuracy: 0.8204 - val_loss: 0.5642 - val_sparse_categorical_accuracy: 0.8107\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5191 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.8179 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.7778\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8504 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8534\n",
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3241 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8679\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8898 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8584\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import tensorflow_addons as tfa\n",
    "opt = tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "mmt=0.1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model3 = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False,\n",
    "                                 kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=0.1,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False,\n",
    "                        kernel_initializer=initializer),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis,momentum=mmt,epsilon=0.00001),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"],\n",
    "                       kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "#\n",
    "model3.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=50,\n",
    "      validation_data=(test_X, test_y)\n",
    ")\n",
    "#\n",
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=1,\n",
    "      validation_data=(test_X, test_y)\n",
    ")\n",
    "#\n",
    "model3.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "history = model3.fit(\n",
    "      x=train_X,\n",
    "      y=train_y,\n",
    "      batch_size=32,\n",
    "      epochs=2,\n",
    "      validation_data=(test_X, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing (Resizing)          (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_flip (RandomFlip)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_zoom (RandomZoom)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 168)       4536      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 168)       672       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 168)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 16, 168)       1512      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 168)       672       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 168)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 276)       46368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 276)       1104      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 276)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 16, 16, 276)       2484      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 276)       1104      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 276)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 276)       76176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 276)       1104      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 276)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 16, 16, 276)       2484      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 276)       1104      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 276)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 276)       76176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 276)       1104      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 276)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 8, 8, 276)         2484      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 276)         1104      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 276)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 276)         76176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 276)         1104      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 276)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 4, 4, 276)         2484      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 276)         1104      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 276)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 276)         76176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 276)         1104      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 276)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 276)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 276)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1104)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                11050     \n",
      "=================================================================\n",
      "Total params: 389,386\n",
      "Trainable params: 383,746\n",
      "Non-trainable params: 5,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
