{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os, sys, json\n",
    "current_path = os.path.abspath('.')\n",
    "parent_path = os.path.dirname(current_path)\n",
    "sys.path.append(parent_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "from src.data_loader import *\n",
    "from src.utils import *\n",
    "\n",
    "from src.models.simple_cnn import *\n",
    "from src.models.resnet_models import *\n",
    "from src.models.dscnn import *\n",
    "from train_joint import *\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################\n",
    "########## Plot Style Declaration ##########\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "# plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.rcParams['font.family'] = 'times new roman'\n",
    "# plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "# plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "##################################\n",
    "########## End of Setup ##########\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgClass():\n",
    "    def __init__(self):\n",
    "        super(ArgClass, self).__init__()\n",
    "\n",
    "args = ArgClass()\n",
    "args.dataset=\"mnist\"\n",
    "args.model_arch = \"cnn\"\n",
    "args.batch_size=128\n",
    "args.test_batch_size=1000\n",
    "args.percent=[0.8, 0.92, 0.991, 0.93]\n",
    "args.alpha=5e-4\n",
    "args.rho=1e-2\n",
    "args.l1=False\n",
    "args.l2=False\n",
    "args.num_pre_epochs=3\n",
    "args.num_epochs=10\n",
    "args.num_re_epochs=3\n",
    "args.lr=1e-3\n",
    "args.adam_epsilon=1e-8\n",
    "args.no_cuda=False\n",
    "args.seed=1\n",
    "args.save_model=False\n",
    "args.shuffle=True\n",
    "\n",
    "args.optimizer_name = 'adam'\n",
    "args.lr_mode = 'multistep'\n",
    "args.lr_decay = 0.1\n",
    "args.lr_decay_epoch = '20,40'\n",
    "args.target_lr = 1e-8\n",
    "args.warmup_epochs = 0\n",
    "args.warmup_lr = 1e-8\n",
    "args.warmup_mode = 'linear'\n",
    "args.momentum = 0.9\n",
    "args.wd = 0.0001\n",
    "args.gamma_wd_mult = 1.0\n",
    "args.beta_wd_mult = 1.0\n",
    "args.bias_wd_mult = 1.0\n",
    "args.grad_clip = None\n",
    "args.label_smoothing = False\n",
    "\n",
    "\n",
    "args.test_fold_l = '[10]'\n",
    "args.use_one_task = 'false'\n",
    "args.exp_setup = ''\n",
    "args.subject_idx = None\n",
    "args.pretrained=False\n",
    "args.best_acc = 200.0\n",
    "args.mixup = False\n",
    "args.mixup_alpha = 1.0\n",
    "args.mixup_epoch_tail = 10\n",
    "args.session = 1\n",
    "args.test_vote = None\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MicroNet-AD-K\n",
    "init_block_channel = 176\n",
    "init_block_stride = (2,2)\n",
    "channels = [[192],[192],[192],[192],[192]]\n",
    "strides = [2, 1, 1, 2, 2]\n",
    "\n",
    "def get_pool_size(strides, config):\n",
    "    pool_size = None\n",
    "    for stride in strides:\n",
    "        if stride > 1:\n",
    "            if pool_size is None:\n",
    "                pool_size=[np.ceil(config[\"seq\"]/2),np.ceil(config[\"features\"]/2)]\n",
    "            else:\n",
    "                pool_size = [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n",
    "    # return pool_size\n",
    "    return [np.ceil(pool_size[0]/2),np.ceil(pool_size[1]/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.backend.image_data_format())\n",
    "# force channels-first ordering\n",
    "# tf.keras.backend.set_image_data_format('channels_first')\n",
    "# print(tf.keras.backend.image_data_format())\n",
    "# bn_axis=1\n",
    "# channel_ordering='channels_first'\n",
    "# force channels-last ordering\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "print(tf.keras.backend.image_data_format())\n",
    "bn_axis=-1\n",
    "channel_ordering='channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "# (args.config[\"features\"]/2)\n",
    "args.dataset='cifar10'\n",
    "train_loader, test_loader = get_data_loaders(args, kwargs)\n",
    "\n",
    "images_l = []\n",
    "labels_l = []\n",
    "for images, labels in test_loader:\n",
    "    images = images.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    if 'channels_last' in channel_ordering:\n",
    "        images = np.transpose(images, (0,2,3,1))\n",
    "    images_l.extend(images)\n",
    "    \n",
    "    labels_l.extend(labels)\n",
    "\n",
    "train_images_l = []\n",
    "train_labels_l = []\n",
    "for images, labels in train_loader:\n",
    "    images = images.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    if 'channels_last' in channel_ordering:\n",
    "        images = np.transpose(images, (0,2,3,1))\n",
    "    train_images_l.extend(images)\n",
    "    train_labels_l.extend(labels)\n",
    "\n",
    "tf_test_dataset = tf.data.Dataset.from_tensor_slices( (images_l, labels_l) )\n",
    "tf_test_dataset = tf_test_dataset.shuffle(buffer_size=100).batch(64)\n",
    "\n",
    "tf_train_dataset = tf.data.Dataset.from_tensor_slices( (train_images_l, train_labels_l) )\n",
    "tf_train_dataset = tf_train_dataset.batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 3, 'features': 32, 'seq': 32, 'classes': 10}\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "args.config = DATASET_CONFIGS[args.dataset]\n",
    "print(args.config)\n",
    "init_block_kernel=(3,3)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "# init_block\n",
    "  tf.keras.layers.Input(shape=[args.config[\"seq\"],args.config[\"features\"],args.config[\"in_channels\"]]),\n",
    "#   tf.keras.layers.Input(shape=[args.config[\"in_channels\"],args.config[\"features\"],args.config[\"seq\"]]),\n",
    "  tf.keras.layers.Conv2D(filters=init_block_channel,kernel_size=init_block_kernel,\n",
    "                        strides=init_block_stride,padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 1st layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=\n",
    "  1,kernel_size=(3,3),\n",
    "                        strides=strides[0],padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[0][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 2nd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[1],padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[1][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 3rd layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[2],padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[2][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 4th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[3],padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[3][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# 5th layer of separable depthwise conv2d\n",
    "  tf.keras.layers.DepthwiseConv2D(depth_multiplier=1,kernel_size=(3,3),\n",
    "                        strides=strides[4],padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Conv2D(filters=channels[4][0],kernel_size=(1,1),\n",
    "                        padding='same',use_bias=False),\n",
    "  tf.keras.layers.BatchNormalization(axis=bn_axis),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "# Note: Add dropout layer after all blocks and before pooling\n",
    "  tf.keras.layers.Dropout(rate=0.4),\n",
    "  tf.keras.layers.AveragePooling2D(pool_size=get_pool_size(strides, args.config),data_format=channel_ordering),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(units=args.config[\"classes\"])\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 176)       4752      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 176)       704       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 176)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 8, 8, 176)         1584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 176)         704       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 176)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 192)         33792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 8, 8, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 8, 8, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 4, 4, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 2, 2, 192)         1728      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 192)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 2, 192)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 192)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1930      \n",
      "=================================================================\n",
      "Total params: 204,746\n",
      "Trainable params: 200,586\n",
      "Non-trainable params: 4,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 713s 910ms/step - loss: 1.8171 - sparse_categorical_accuracy: 0.3245 - val_loss: 1.4774 - val_sparse_categorical_accuracy: 0.4875\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fd857ed96a0>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, epochs=1, validation_data=tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/zz/mkr3s_81101_rh7kxcgvf7l80000gn/T/tmpo0c583i2/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "252704"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    \"\"\"Generator function to produce representative dataset for post-training quantization.\"\"\"\n",
    "    # Use a few samples from the training set.\n",
    "    for _ in range(100):\n",
    "        img = iter(train_loader).next()[0].numpy()\n",
    "        img = np.transpose( img , (0,2,3,1) )\n",
    "        img = [(img.astype(np.float32))]\n",
    "        yield img\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = get_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"../data/tflite_model/MicroNet-AD-I176_S22_cifar10_int8.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! xxd -i ../data/tflite_model/MicroNet-AD-I168_cifar10_int8.tflite > ../data/tflite_model/MicroNet-AD-I168_cifar10_int8.cc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "name": "python388jvsc74a57bd0003f9127b5ced653bd2b878879d78e4110a6e981d8afcde6329575d6beee66d8"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}