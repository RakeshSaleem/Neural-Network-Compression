{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os, sys, json\n",
    "current_path = os.path.abspath('.')\n",
    "parent_path = os.path.dirname(current_path)\n",
    "sys.path.append(parent_path)\n",
    "import argparse\n",
    "import collections,math\n",
    "import time,datetime,pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import unittest\n",
    "\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy import stats\n",
    "from scipy import interpolate, io\n",
    "from scipy.io import loadmat\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import faiss\n",
    "\n",
    "from src.data_loader import *\n",
    "from src.utils import *\n",
    "\n",
    "from src.models.simple_cnn import *\n",
    "from src.models.resnet_models import *\n",
    "from src.models.dscnn import *\n",
    "from train_joint import *\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################\n",
    "########## Plot Style Declaration ##########\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "# plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.rcParams['font.family'] = 'times new roman'\n",
    "# plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "# plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "##################################\n",
    "########## End of Setup ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgClass():\n",
    "    def __init__(self):\n",
    "        super(ArgClass, self).__init__()\n",
    "\n",
    "args = ArgClass()\n",
    "args.dataset=\"mnist\"\n",
    "args.model_arch = \"cnn\"\n",
    "args.batch_size=128\n",
    "args.test_batch_size=1000\n",
    "args.percent=[0.8, 0.92, 0.991, 0.93]\n",
    "args.alpha=5e-4\n",
    "args.rho=1e-2\n",
    "args.l1=False\n",
    "args.l2=False\n",
    "args.num_pre_epochs=3\n",
    "args.num_epochs=5\n",
    "args.num_re_epochs=3\n",
    "args.lr=1e-3\n",
    "args.adam_epsilon=1e-8\n",
    "args.no_cuda=True\n",
    "args.seed=1\n",
    "args.save_model=False\n",
    "args.shuffle=True\n",
    "\n",
    "args.optimizer_name = 'adam'\n",
    "args.lr_mode = 'multistep'\n",
    "args.lr_decay = 0.1\n",
    "args.lr_decay_epoch = '20,40'\n",
    "args.target_lr = 1e-8\n",
    "args.warmup_epochs = 0\n",
    "args.warmup_lr = 1e-8\n",
    "args.warmup_mode = 'linear'\n",
    "args.momentum = 0.9\n",
    "args.wd = 0.0001\n",
    "args.gamma_wd_mult = 1.0\n",
    "args.beta_wd_mult = 1.0\n",
    "args.bias_wd_mult = 1.0\n",
    "args.grad_clip = None\n",
    "args.label_smoothing = False\n",
    "\n",
    "\n",
    "args.test_fold_l = '[10]'\n",
    "args.use_one_task = 'false'\n",
    "args.exp_setup = ''\n",
    "args.subject_idx = None\n",
    "args.pretrained=False\n",
    "args.best_acc = 200.0\n",
    "args.mixup = False\n",
    "args.mixup_alpha = 1.0\n",
    "args.mixup_epoch_tail = 10\n",
    "args.session = 1\n",
    "args.test_vote = None\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "class PTCVDSCNNQuant(nn.Module):\n",
    "    def __init__(self, model_name=\"dscnn_l\", in_channels=1, num_classes=12, init_block_kernel=(10,4), pretrained=False, **kwargs):\n",
    "        super(PTCVDSCNNQuant, self).__init__()\n",
    "        self.model = get_dscnn(model_name=model_name.lower(),\n",
    "                               in_channels=in_channels,\n",
    "                               num_classes=num_classes,\n",
    "                               init_block_kernel=init_block_kernel,\n",
    "                               pretrained=pretrained,\n",
    "                               **kwargs)\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class AudioCNNQuant(nn.Module):\n",
    "    def __init__(self,\n",
    "                 channels=[32,32,64,64],\n",
    "                 in_channels=1,\n",
    "                 in_size=(32, 32),\n",
    "                 num_classes=10,\n",
    "                 pooling_type='avg'\n",
    "                 ):\n",
    "        super(AudioCNNQuant, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels,channels[0],kernel_size=(3, 3),stride=1,padding=1),\n",
    "                        nn.BatchNorm2d(channels[0]),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(channels[0], channels[1], kernel_size=(3, 3), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(channels[1]),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.MaxPool2d(2, stride=2) if pooling_type == 'max' else nn.AvgPool2d(2, stride=2)\n",
    "                    )\n",
    "        self.conv3 = nn.Sequential(\n",
    "                        nn.Conv2d(channels[1], channels[2], kernel_size=(3, 3), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(channels[2]),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    )\n",
    "        self.conv4 = nn.Sequential(\n",
    "                        nn.Conv2d(channels[2], channels[3], kernel_size=(3, 3), stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(channels[3]),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.MaxPool2d(2, stride=2) if pooling_type == 'max' else nn.AvgPool2d(2, stride=2)\n",
    "                    )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        features_dim, seq_dim = get_feature_seq_dim(4, in_size)\n",
    "        self.fc = nn.Linear(channels[3]*features_dim*seq_dim, num_classes)\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x = self.dequant(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "class VWNetQuant(nn.Module):\n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 in_channels=1,\n",
    "                 in_size=(32, 32),\n",
    "                 channels=[32, 32, 64, 64],\n",
    "                 fcDims=[128, 128],\n",
    "                 kernels=[(3,3)],\n",
    "                 num_classes=10,\n",
    "                 pooling_type='avg'\n",
    "                 ):\n",
    "        super(VWNetQuant, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module(\"init_block\",\n",
    "             nn.Sequential(\n",
    "                 nn.Conv2d(in_channels, channels[0], kernel_size=kernels[0], stride=1,padding=0),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.MaxPool2d(2, stride=2) if pooling_type == 'max' else nn.AvgPool2d(2, stride=2))\n",
    "         )\n",
    "\n",
    "        for i, channels_per_stage in enumerate(channels):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            self.features.add_module(\"stage{}\".format(i),\n",
    "                 nn.Sequential(\n",
    "                     nn.Conv2d(channels[i-1], channels[i], kernel_size=kernels[i] if len(kernels)>1 else kernels[0], stride=1,padding=0),\n",
    "                     nn.ReLU(inplace=True),\n",
    "                     nn.MaxPool2d(2, stride=2) if pooling_type == 'max' else nn.AvgPool2d(2, stride=2))\n",
    "             )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        features_dim, seq_dim = get_feature_seq_dim_nopadding(len(channels), in_size, kernels)\n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.add_module(\"init_decoder\",\n",
    "            nn.Sequential(\n",
    "                nn.Linear(channels[-1] * features_dim * seq_dim, fcDims[0]),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5))\n",
    "        )\n",
    "\n",
    "        if len(fcDims) > 1:\n",
    "            for i, channels_per_stage in enumerate(fcDims):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                self.decoder.add_module(\"decode_stage{}\".format(i),\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(fcDims[i-1], fcDims[i]),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Dropout(0.5))\n",
    "                )\n",
    "\n",
    "        self.output = nn.Linear(fcDims[-1], num_classes)\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        # print(x.size())\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        x = self.output(x)\n",
    "        x = self.dequant(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90.05\n",
    "args.config = DATASET_CONFIGS['cifar10']\n",
    "cifar10 = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch168', in_channels=args.config[\"in_channels\"],\n",
    "                             num_classes=args.config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=False)\n",
    "cifar10.load_state_dict(torch.load('../data/saved_model/MicroNet-AD-I-ch168_cifar10_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "# 94.48\n",
    "args.config = DATASET_CONFIGS['svhn']\n",
    "svhn = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch168', in_channels=args.config[\"in_channels\"],\n",
    "                             num_classes=args.config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=False)\n",
    "svhn.load_state_dict(torch.load('../data/saved_model/MicroNet-AD-I-ch168_svhn_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "# 97.50\n",
    "args.config = DATASET_CONFIGS['gtsrb-vw']\n",
    "gtsrb = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch168', in_channels=args.config[\"in_channels\"],\n",
    "                             num_classes=args.config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=False)\n",
    "gtsrb.load_state_dict(torch.load('../data/saved_model/MicroNet-AD-I-ch168_gtsrb-vw_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "# 78.9\n",
    "config = DATASET_CONFIGS['hhar-noaug']\n",
    "hhar = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch176-s41', in_channels=1,\n",
    "                             num_classes=config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=args.pretrained)\n",
    "hhar.load_state_dict(torch.load('../data/saved_model/MicroNet-hhar-ch176_hhar-noaug_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "\n",
    "\n",
    "# 73.0\n",
    "config = DATASET_CONFIGS['stl10']\n",
    "stl10 = PTCVDSCNNQuant(model_name='DS-CNN-M-s33', in_channels=config[\"in_channels\"],\n",
    "                             num_classes=config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=args.pretrained)\n",
    "stl10.load_state_dict(torch.load('../data/saved_model/DS-CNN-M-s33_stl10_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "# 93.47\n",
    "config = DATASET_CONFIGS['urbansound8k-LMCST-long-randfold']\n",
    "urbansound = PTCVDSCNNQuant(model_name='DS-CNN-M-s33', in_channels=1,\n",
    "                             num_classes=config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=args.pretrained)\n",
    "urbansound.load_state_dict(torch.load('../data/saved_model/DS-CNN-M-s33_urbansound8k-LMCST-long-randfold_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "\n",
    "# Unseen HAR\n",
    "# 91.5\n",
    "config = DATASET_CONFIGS['pamap2']\n",
    "pamap2 = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch168-s21', in_channels=1,\n",
    "                             num_classes=config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=args.pretrained)\n",
    "pamap2.load_state_dict(torch.load('../data/saved_model/MicroNet-AD-I-ch168-s21_pamap2_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n",
    "# 97.65\n",
    "config = DATASET_CONFIGS['skoda']\n",
    "skoda = PTCVDSCNNQuant(model_name='MicroNet-AD-I-ch192-s22', in_channels=1,\n",
    "                             num_classes=config[\"classes\"],\n",
    "                             init_block_kernel=(3, 3),\n",
    "                             pretrained=args.pretrained)\n",
    "skoda.load_state_dict(torch.load('../data/saved_model/MicroNet-AD-I-ch192-s22_skoda_adam_multistep_nomixup.pt', map_location=device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data-link/image/svhn/train_32x32.mat\n",
      "Using downloaded and verified file: ../data-link/image/svhn/test_32x32.mat\n",
      "X.shape:  (39209, 1, 32, 32)\n",
      "y.shape:  (39209,)\n",
      "X.shape:  (12630, 1, 32, 32)\n",
      "y.shape:  (12630,)\n",
      "X.shape:  (59403, 1, 20, 120)\n",
      "y.shape:  (59403,)\n",
      "X.shape:  (7721, 1, 20, 120)\n",
      "y.shape:  (7721,)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "X.shape:  (7859, 1, 128, 85)\n",
      "y.shape:  (7859,)\n",
      "X.shape:  (873, 1, 128, 85)\n",
      "y.shape:  (873,)\n",
      "The shape of the train dataset is 52, and the labels is 473445\n",
      "The shape of the val dataset is 52, and the labels is 90814\n",
      "The shape of the test dataset is 52, and the labels is 83366\n",
      "X.shape:  (35263, 1, 33, 52)\n",
      "y.shape:  (35263,)\n",
      "X.shape:  (5209, 1, 33, 52)\n",
      "y.shape:  (5209,)\n",
      "The shape of the train dataset is 60, and the labels is 143825\n",
      "The shape of the val dataset is 60, and the labels is 16976\n",
      "The shape of the test dataset is 60, and the labels is 19115\n",
      "X.shape:  (10047, 1, 33, 60)\n",
      "y.shape:  (10047,)\n",
      "X.shape:  (1193, 1, 33, 60)\n",
      "y.shape:  (1193,)\n"
     ]
    }
   ],
   "source": [
    "# Lee's datasets\n",
    "# args.dataset = 'mnist'\n",
    "# train_loader_mnist, test_loader_mnist = get_data_loaders(args, kwargs)\n",
    "args.dataset='cifar10'\n",
    "train_loader_cifar10, test_loader_cifar10 = get_data_loaders(args, kwargs)\n",
    "args.dataset='svhn'\n",
    "train_loader_svhn, test_loader_svhn = get_data_loaders(args, kwargs)\n",
    "args.dataset='gtsrb-vw'\n",
    "train_loader_gtsrb, test_loader_gtsrb = get_data_loaders(args, kwargs)\n",
    "# args.dataset='gscv2-mfcc10'\n",
    "# train_loader_gsc, test_loader_gsc = get_data_loaders(args, kwargs)\n",
    "\n",
    "# additional datasets to be trained \n",
    "args.dataset = 'hhar-noaug'\n",
    "train_loader_hhar, test_loader_hhar = get_data_loaders(args, kwargs)\n",
    "# args.dataset = 'ninapro-db2-c10'\n",
    "# args.subject_idx=11\n",
    "# args.exp_setup='per-subject'\n",
    "# train_loader_ninadb2, test_loader_ninadb2 = get_data_loaders(args, kwargs)\n",
    "\n",
    "# unseen datasets\n",
    "# args.dataset = 'fashion-mnist'\n",
    "# train_loader_fmnist, test_loader_fmnist = get_data_loaders(args, kwargs)\n",
    "args.dataset = 'stl10'\n",
    "train_loader_stl10, test_loader_stl10 = get_data_loaders(args, kwargs)\n",
    "\n",
    "# args.dataset = 'emotion-5-frames25'\n",
    "# train_loader_emotion, test_loader_emotion = get_data_loaders(args, kwargs)\n",
    "args.dataset = 'urbansound8k-LMCST-long-randfold'\n",
    "train_loader_urbansound, test_loader_urbansound = get_data_loaders(args, kwargs)\n",
    "\n",
    "args.dataset = 'pamap2'\n",
    "train_loader_pamap2, test_loader_pamap2 = get_data_loaders(args, kwargs)\n",
    "args.dataset = 'skoda'\n",
    "train_loader_skoda, test_loader_skoda = get_data_loaders(args, kwargs)\n",
    "\n",
    "# args.dataset = 'ninapro-db3-c10'\n",
    "# args.subject_idx=1\n",
    "# train_loader_ninadb3, test_loader_ninadb3 = get_data_loaders(args, kwargs)\n",
    "# args.dataset = 'ninapro-db6-c7-seq80'\n",
    "# train_loader_ninadb6, test_loader_ninadb6 = get_data_loaders(args, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    model_size = os.path.getsize(\"temp.p\")/1e6\n",
    "    print('Size (MB):', model_size)\n",
    "    os.remove('temp.p')\n",
    "    return model_size\n",
    "\n",
    "def get_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    model_size = os.path.getsize(\"temp.p\")/1e6\n",
    "    os.remove('temp.p')\n",
    "    return model_size\n",
    "\n",
    "def train(args, model, device, train_loader, test_loader, optimizer):\n",
    "    args.best_acc = -0.1\n",
    "    for epoch in range(args.num_epochs):\n",
    "        print(f'Epoch: {epoch+1:5d}')\n",
    "        args.epoch = epoch + 1\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if args.mixup and (epoch < args.num_epochs - args.mixup_epoch_tail) :\n",
    "                data, target_a, target_b, lam = mixup_data(data, target, device, alpha=args.mixup_alpha)\n",
    "                output = model(data)\n",
    "                loss = mixup_loss(args, model, output, target_a, target_b, lam)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = regularized_nll_loss(args, model, output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc = test(args, model, device, train_loader, 3)\n",
    "        test_acc = test(args, model, device, test_loader, 3)\n",
    "        if train_acc > 70.:\n",
    "            break\n",
    "\n",
    "def test(args, model, device, test_loader, neval_batches):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for cnt, (data, target) in enumerate(test_loader):\n",
    "            if args.test_vote is None:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            elif args.test_vote == 'avg_pool_vote':\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                tot_window_size = data.size()[3] # NCHW\n",
    "                window_size = args.config['seq']\n",
    "                window_stride = args.config['seq']\n",
    "                for i in range(0, tot_window_size, window_stride):\n",
    "                    data_temp = data[:,:,:,i*window_stride:i*window_stride+window_size] if i*window_stride+window_size <= tot_window_size else data[:,:,:,-1-window_size:-1]\n",
    "                    output_temp = model(data_temp)\n",
    "                    test_loss += F.nll_loss(output_temp, target, reduction='sum').item()  # sum up batch loss\n",
    "                    if i == 0:\n",
    "                        output = output_temp\n",
    "                    else:\n",
    "                        output += output_temp\n",
    "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            if cnt >= neval_batches:\n",
    "                neval = (cnt+1)*data.size(0)\n",
    "                test_loss /= neval\n",
    "                \n",
    "                print('\\nTrain or Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "                test_loss, correct, neval,\n",
    "                100. * correct / neval))\n",
    "                return 100. * correct / neval\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTrain or Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    if args.best_acc < 100. * correct / len(test_loader.dataset):\n",
    "        args.best_acc = 100. * correct / len(test_loader.dataset)\n",
    "        args.best_acc_epoch = args.epoch\n",
    "        print(f'New Best Accuracy: ({args.best_acc:.2f}%) at Epoch: ({args.best_acc_epoch})\\n')\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "        \n",
    "def staticQuantizePerTensor(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    \n",
    "    myModel = copy.deepcopy(rModel.to('cpu'))\n",
    "    myModel.eval()\n",
    "    size_prev = get_size_of_model(myModel)\n",
    "\n",
    "    # Specify quantization configuration\n",
    "    # Start with simple min/max range estimation and per-tensor quantization of weights\n",
    "    myModel.qconfig = torch.quantization.default_qconfig\n",
    "    print(myModel.qconfig)\n",
    "    torch.quantization.prepare(myModel, inplace=True)\n",
    "\n",
    "    # Calibrate with the training set\n",
    "    acc_prev = test(args, myModel.to(device), device, train_loader, num_calibration_batches)\n",
    "    print('Post Training Quantization: Calibration done')\n",
    "\n",
    "    # Convert to quantized model\n",
    "    torch.quantization.convert(myModel, inplace=True)\n",
    "    print('Post Training Quantization: Convert done')\n",
    "\n",
    "    size_curr = get_size_of_model(myModel)\n",
    "\n",
    "    acc_curr = test(args, myModel.to(device), device, test_loader, num_eval_batches)\n",
    "    print(f'Size Prev (MB): {size_prev}, Size Current (MB): {size_curr}, Comp Rate: {size_prev/size_curr} ')\n",
    "    return acc_prev, acc_curr, size_prev/size_curr\n",
    "\n",
    "def getResult4Quant(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    ret_l = []\n",
    "#     acc_curr_l = []\n",
    "#     comp_rate_l = []\n",
    "    for i in range(5):\n",
    "        torch.manual_seed(i)\n",
    "        ret = staticQuantizePerTensor(args,rModel,train_loader,test_loader,num_calibration_batches,num_eval_batches)\n",
    "        ret_l.append(ret)\n",
    "    ret_l = np.array(ret_l)\n",
    "    print(ret_l)\n",
    "    print(f'Accuracy: {np.mean(ret_l[:,1])}, Acc_Std: {np.std(ret_l[:,1])}, Comp Rate Avg.: {np.mean(ret_l[:,2])}, Comp Rate Std.: {np.std(ret_l[:,2])}')\n",
    "\n",
    "    \n",
    "def staticQuantizePerChannel(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    \n",
    "    myModel = copy.deepcopy(rModel.to('cpu'))\n",
    "    myModel.eval()\n",
    "    size_prev = get_size_of_model(myModel)\n",
    "\n",
    "    # Specify quantization configuration\n",
    "    # Start with simple min/max range estimation and per-tensor quantization of weights\n",
    "    myModel.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "    print(myModel.qconfig)\n",
    "    torch.quantization.prepare(myModel, inplace=True)\n",
    "\n",
    "    # Calibrate with the training set\n",
    "    acc_prev = test(args, myModel.to(device), device, train_loader, num_calibration_batches)\n",
    "    print('Post Training Quantization: Calibration done')\n",
    "\n",
    "    # Convert to quantized model\n",
    "    torch.quantization.convert(myModel, inplace=True)\n",
    "    print('Post Training Quantization: Convert done')\n",
    "\n",
    "    size_curr = get_size_of_model(myModel)\n",
    "\n",
    "    acc_curr = test(args, myModel.to(device), device, test_loader, num_eval_batches)\n",
    "    print(f'Size Prev (MB): {size_prev}, Size Current (MB): {size_curr}, Comp Rate: {size_prev/size_curr} ')\n",
    "    return acc_prev, acc_curr, size_prev/size_curr\n",
    "\n",
    "def getResult4QuantChannel(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    ret_l = []\n",
    "#     acc_curr_l = []\n",
    "#     comp_rate_l = []\n",
    "    for i in range(5):\n",
    "        torch.manual_seed(i)\n",
    "        ret = staticQuantizePerChannel(args,rModel,train_loader,test_loader,num_calibration_batches,num_eval_batches)\n",
    "        ret_l.append(ret)\n",
    "    ret_l = np.array(ret_l)\n",
    "    print(ret_l)\n",
    "    print(f'Accuracy: {np.mean(ret_l[:,1])}, Acc_Std: {np.std(ret_l[:,1])}, Comp Rate Avg.: {np.mean(ret_l[:,2])}, Comp Rate Std.: {np.std(ret_l[:,2])}')\n",
    "    \n",
    "\n",
    "def qaQuantizePerChannel(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    \n",
    "    myModel = copy.deepcopy(rModel.to(device))\n",
    "    myModel.eval()\n",
    "    size_prev = get_size_of_model(myModel)\n",
    "\n",
    "    # Specify quantization configuration\n",
    "    # Start with simple min/max range estimation and per-tensor quantization of weights\n",
    "    # optimizer = torch.optim.SGD(myModel.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.Adam(myModel.parameters(), lr = 0.001, betas=(0.9, 0.999),weight_decay=0.0001)\n",
    "    \n",
    "    myModel.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    print(myModel.qconfig)\n",
    "    torch.quantization.prepare_qat(myModel, inplace=True)\n",
    "\n",
    "    # Calibrate with the training set\n",
    "    acc_prev = test(args, myModel.to(device), device, train_loader, num_calibration_batches)\n",
    "    print('Post Training Quantization: Calibration done')\n",
    "    \n",
    "    for nepoch in range(3):\n",
    "        train(args, myModel.to(device), device, train_loader, test_loader, optimizer)\n",
    "        \n",
    "        if nepoch > 3:\n",
    "            # Freeze quantizer parameters\n",
    "            myModel.apply(torch.quantization.disable_observer)\n",
    "        if nepoch > 2:\n",
    "            # Freeze batch norm mean and variance estimates\n",
    "            myModel.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
    "        \n",
    "        quantized_model = torch.quantization.convert(myModel.to('cpu').eval(), inplace=False)\n",
    "        quantized_model.eval()\n",
    "        acc_curr = test(args, quantized_model.to('cpu'), 'cpu', test_loader, 10)\n",
    "        print(f'MY Current Accuracy: {acc_curr}, at Epoch: {nepoch}')\n",
    "    \n",
    "    # Convert to quantized model\n",
    "    torch.quantization.convert(myModel.to('cpu'), inplace=True)\n",
    "    print('Post Training Quantization: Convert done')\n",
    "\n",
    "    size_curr = get_size_of_model(myModel)\n",
    "\n",
    "    acc_curr = test(args, myModel.to('cpu'), 'cpu', test_loader, num_eval_batches)\n",
    "    print(f'Size Prev (MB): {size_prev}, Size Current (MB): {size_curr}, Comp Rate: {size_prev/size_curr} ')\n",
    "    return acc_prev, acc_curr, size_prev/size_curr\n",
    "\n",
    "def getResult4qaQuantChannel(args, rModel, train_loader, test_loader, num_calibration_batches=32,num_eval_batches=1000):\n",
    "    ret_l = []\n",
    "#     acc_curr_l = []\n",
    "#     comp_rate_l = []\n",
    "    for i in range(5):\n",
    "        torch.manual_seed(i)\n",
    "        ret = qaQuantizePerChannel(args,rModel,train_loader,test_loader,num_calibration_batches,num_eval_batches)\n",
    "        ret_l.append(ret)\n",
    "    ret_l = np.array(ret_l)\n",
    "    print(ret_l)\n",
    "    print(f'Accuracy: {np.mean(ret_l[:,1])}, Acc_Std: {np.std(ret_l[:,1])}, Comp Rate Avg.: {np.mean(ret_l[:,2])}, Comp Rate Std.: {np.std(ret_l[:,2])}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results below (Seen Models)\n",
    "num_calibration_batches = 32\n",
    "num_eval_batches = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0758, Accuracy: 4123/4224 (97.61%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3926, Accuracy: 8901/10000 (89.01%)\n",
      "Size Prev (MB): 0.837056, Size Current (MB): 0.302188, Comp Rate: 2.769984248216342 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0814, Accuracy: 4117/4224 (97.47%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4073, Accuracy: 8872/10000 (88.72%)\n",
      "Size Prev (MB): 0.837058, Size Current (MB): 0.302252, Comp Rate: 2.769404338101981 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0748, Accuracy: 4121/4224 (97.56%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3955, Accuracy: 8881/10000 (88.81%)\n",
      "Size Prev (MB): 0.837054, Size Current (MB): 0.302245, Comp Rate: 2.769455243262916 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0702, Accuracy: 4128/4224 (97.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4292, Accuracy: 8816/10000 (88.16%)\n",
      "Size Prev (MB): 0.837043, Size Current (MB): 0.302242, Comp Rate: 2.7694463377029 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0814, Accuracy: 4116/4224 (97.44%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3897, Accuracy: 8911/10000 (89.11%)\n",
      "Size Prev (MB): 0.837062, Size Current (MB): 0.302243, Comp Rate: 2.7695000380488546 \n",
      "[[97.60890152 89.01        2.76998425]\n",
      " [97.46685606 88.72        2.76940434]\n",
      " [97.56155303 88.81        2.76945524]\n",
      " [97.72727273 88.16        2.76944634]\n",
      " [97.44318182 89.11        2.76950004]]\n",
      "Accuracy: 88.76200000000001, Acc_Std: 0.33138497250177373, Comp Rate Avg.: 2.769558041066599, Comp Rate Std.: 0.00021526101170243217\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,cifar10,train_loader_cifar10,test_loader_cifar10,32,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.1233, Accuracy: 4075/4224 (96.47%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2200, Accuracy: 24422/26032 (93.82%)\n",
      "Size Prev (MB): 0.837056, Size Current (MB): 0.30216, Comp Rate: 2.7702409319565797 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.1332, Accuracy: 4064/4224 (96.21%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2147, Accuracy: 24444/26032 (93.90%)\n",
      "Size Prev (MB): 0.83696, Size Current (MB): 0.302086, Comp Rate: 2.770601749170766 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.1357, Accuracy: 4062/4224 (96.16%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2281, Accuracy: 24376/26032 (93.64%)\n",
      "Size Prev (MB): 0.837035, Size Current (MB): 0.30215, Comp Rate: 2.7702631143471788 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.1315, Accuracy: 4080/4224 (96.59%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2310, Accuracy: 24346/26032 (93.52%)\n",
      "Size Prev (MB): 0.837033, Size Current (MB): 0.302147, Comp Rate: 2.7702840008340313 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.1256, Accuracy: 4084/4224 (96.69%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2322, Accuracy: 24341/26032 (93.50%)\n",
      "Size Prev (MB): 0.837031, Size Current (MB): 0.302088, Comp Rate: 2.7708184370117315 \n",
      "[[96.47253788 93.81530424  2.77024093]\n",
      " [96.21212121 93.89981561  2.77060175]\n",
      " [96.16477273 93.63859865  2.77026311]\n",
      " [96.59090909 93.52335587  2.770284  ]\n",
      " [96.68560606 93.50414874  2.77081844]]\n",
      "Accuracy: 93.67624462200368, Acc_Std: 0.15730908908145325, Comp Rate Avg.: 2.770441646664058, Comp Rate Std.: 0.00023005050247597818\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,svhn,train_loader_svhn,test_loader_svhn,32,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.0940, Accuracy: 12306/12630 (97.43%)\n",
      "Size Prev (MB): 0.850406, Size Current (MB): 0.306054, Comp Rate: 2.7786142314754914 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.0945, Accuracy: 12294/12630 (97.34%)\n",
      "Size Prev (MB): 0.850409, Size Current (MB): 0.306049, Comp Rate: 2.7786694287516047 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.0943, Accuracy: 12310/12630 (97.47%)\n",
      "Size Prev (MB): 0.850402, Size Current (MB): 0.30605, Comp Rate: 2.7786374775363503 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.0948, Accuracy: 12299/12630 (97.38%)\n",
      "Size Prev (MB): 0.850405, Size Current (MB): 0.306049, Comp Rate: 2.778656358949057 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.0952, Accuracy: 12298/12630 (97.37%)\n",
      "Size Prev (MB): 0.850401, Size Current (MB): 0.30605, Comp Rate: 2.7786342100963894 \n",
      "[[100.          97.43467933   2.77861423]\n",
      " [100.          97.33966746   2.77866943]\n",
      " [100.          97.46634996   2.77863748]\n",
      " [100.          97.37925574   2.77865636]\n",
      " [100.          97.37133808   2.77863421]]\n",
      "Accuracy: 97.39825811559778, Acc_Std: 0.04578569214505492, Comp Rate Avg.: 2.7786423413617785, Comp Rate Std.: 1.9027135477553156e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,gtsrb,train_loader_gtsrb,test_loader_gtsrb,32,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0005, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.5056, Accuracy: 5409/7721 (70.06%)\n",
      "Size Prev (MB): 0.829154, Size Current (MB): 0.300604, Comp Rate: 2.758293302816995 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.6920, Accuracy: 5190/7721 (67.22%)\n",
      "Size Prev (MB): 0.829153, Size Current (MB): 0.300601, Comp Rate: 2.758317503933786 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.8926, Accuracy: 4989/7721 (64.62%)\n",
      "Size Prev (MB): 0.829155, Size Current (MB): 0.300603, Comp Rate: 2.758305805331284 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.6510, Accuracy: 5385/7721 (69.74%)\n",
      "Size Prev (MB): 0.829088, Size Current (MB): 0.300604, Comp Rate: 2.758073744860348 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0005, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.8321, Accuracy: 4954/7721 (64.16%)\n",
      "Size Prev (MB): 0.829158, Size Current (MB): 0.300608, Comp Rate: 2.758269906323185 \n",
      "[[100.          70.05569227   2.7582933 ]\n",
      " [100.          67.21927212   2.7583175 ]\n",
      " [100.          64.61598239   2.75830581]\n",
      " [100.          69.7448517    2.75807374]\n",
      " [100.          64.16267323   2.75826991]]\n",
      "Accuracy: 67.15969434011139, Acc_Std: 2.470870217095648, Comp Rate Avg.: 2.75825205265312, Comp Rate Std.: 9.053973610337057e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.3035, Accuracy: 3815/4224 (90.32%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8436, Accuracy: 5796/8000 (72.45%)\n",
      "Size Prev (MB): 0.567652, Size Current (MB): 0.212575, Comp Rate: 2.670361049041515 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.3152, Accuracy: 3790/4224 (89.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8339, Accuracy: 5810/8000 (72.62%)\n",
      "Size Prev (MB): 0.567662, Size Current (MB): 0.212576, Comp Rate: 2.670395529128406 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.3119, Accuracy: 3796/4224 (89.87%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8430, Accuracy: 5768/8000 (72.10%)\n",
      "Size Prev (MB): 0.567662, Size Current (MB): 0.212644, Comp Rate: 2.6695415812343635 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.3179, Accuracy: 3785/4224 (89.61%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8583, Accuracy: 5740/8000 (71.75%)\n",
      "Size Prev (MB): 0.567661, Size Current (MB): 0.212642, Comp Rate: 2.6695619868135174 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.3138, Accuracy: 3791/4224 (89.75%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8410, Accuracy: 5783/8000 (72.29%)\n",
      "Size Prev (MB): 0.567659, Size Current (MB): 0.212575, Comp Rate: 2.67039397859579 \n",
      "[[90.31723485 72.45        2.67036105]\n",
      " [89.72537879 72.625       2.67039553]\n",
      " [89.86742424 72.1         2.66954158]\n",
      " [89.60700758 71.75        2.66956199]\n",
      " [89.74905303 72.2875      2.67039398]]\n",
      "Accuracy: 72.24249999999999, Acc_Std: 0.30141333746203147, Comp Rate Avg.: 2.670050824962719, Comp Rate Std.: 0.000407702408082402\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,stl10,train_loader_stl10,test_loader_stl10,32,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0007, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3667, Accuracy: 792/873 (90.72%)\n",
      "Size Prev (MB): 0.555242, Size Current (MB): 0.209504, Comp Rate: 2.650269207270506 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3893, Accuracy: 782/873 (89.58%)\n",
      "Size Prev (MB): 0.555235, Size Current (MB): 0.2095, Comp Rate: 2.6502863961813845 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3852, Accuracy: 781/873 (89.46%)\n",
      "Size Prev (MB): 0.555238, Size Current (MB): 0.209563, Comp Rate: 2.649503967780572 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0007, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3269, Accuracy: 802/873 (91.87%)\n",
      "Size Prev (MB): 0.55524, Size Current (MB): 0.209562, Comp Rate: 2.6495261545509203 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0006, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3242, Accuracy: 797/873 (91.29%)\n",
      "Size Prev (MB): 0.55525, Size Current (MB): 0.209504, Comp Rate: 2.6503073926989464 \n",
      "[[100.          90.72164948   2.65026921]\n",
      " [100.          89.57617411   2.6502864 ]\n",
      " [100.          89.46162658   2.64950397]\n",
      " [100.          91.86712486   2.64952615]\n",
      " [100.          91.29438717   2.65030739]]\n",
      "Accuracy: 90.58419243986255, Acc_Std: 0.9429148053725885, Comp Rate Avg.: 2.6499786236964655, Comp Rate Std.: 0.00037875541953371955\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,urbansound,train_loader_urbansound,test_loader_urbansound,32,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0004, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4301, Accuracy: 4678/5209 (89.81%)\n",
      "Size Prev (MB): 0.826388, Size Current (MB): 0.299445, Comp Rate: 2.7597321711833556 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0005, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.5081, Accuracy: 4623/5209 (88.75%)\n",
      "Size Prev (MB): 0.826471, Size Current (MB): 0.299447, Comp Rate: 2.75999091658958 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0003, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4671, Accuracy: 4666/5209 (89.58%)\n",
      "Size Prev (MB): 0.826466, Size Current (MB): 0.299444, Comp Rate: 2.760001870132646 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0003, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4795, Accuracy: 4677/5209 (89.79%)\n",
      "Size Prev (MB): 0.826466, Size Current (MB): 0.299449, Comp Rate: 2.7599557854592933 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0003, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.4997, Accuracy: 4652/5209 (89.31%)\n",
      "Size Prev (MB): 0.826467, Size Current (MB): 0.299451, Comp Rate: 2.7599406914653812 \n",
      "[[100.          89.80610482   2.75973217]\n",
      " [100.          88.75023997   2.75999092]\n",
      " [100.          89.57573431   2.76000187]\n",
      " [100.          89.78690728   2.75995579]\n",
      " [100.          89.30696871   2.75994069]]\n",
      "Accuracy: 89.44519101555, Acc_Std: 0.39144161492595114, Comp Rate Avg.: 2.7599242869660516, Comp Rate Std.: 9.861885327460326e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,pamap2,train_loader_pamap2,test_loader_pamap2,32,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0002, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2935, Accuracy: 1099/1193 (92.12%)\n",
      "Size Prev (MB): 0.77635, Size Current (MB): 0.283962, Comp Rate: 2.7339925764714996 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0002, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2504, Accuracy: 1113/1193 (93.29%)\n",
      "Size Prev (MB): 0.776418, Size Current (MB): 0.283961, Comp Rate: 2.7342416740327016 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0002, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3553, Accuracy: 1084/1193 (90.86%)\n",
      "Size Prev (MB): 0.776349, Size Current (MB): 0.28396, Comp Rate: 2.7340083110297226 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0002, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.3377, Accuracy: 1092/1193 (91.53%)\n",
      "Size Prev (MB): 0.776419, Size Current (MB): 0.283966, Comp Rate: 2.734197051759718 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
      "\n",
      "Train or Test set: Average loss: 0.0002, Accuracy: 4224/4224 (100.00%)\n",
      "Post Training Quantization: Calibration done\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.2563, Accuracy: 1108/1193 (92.88%)\n",
      "Size Prev (MB): 0.776351, Size Current (MB): 0.283963, Comp Rate: 2.733986470068283 \n",
      "[[100.          92.12070411   2.73399258]\n",
      " [100.          93.29421626   2.73424167]\n",
      " [100.          90.86336966   2.73400831]\n",
      " [100.          91.53394803   2.73419705]\n",
      " [100.          92.87510478   2.73398647]]\n",
      "Accuracy: 92.13746856663872, Acc_Std: 0.8797748039163064, Comp Rate Avg.: 2.734085216672385, Comp Rate Std.: 0.00011066487145521959\n"
     ]
    }
   ],
   "source": [
    "getResult4QuantChannel(args,skoda,train_loader_skoda,test_loader_skoda,32,10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QAT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:02<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5208, Accuracy: 5236/7721 (67.82%)\n",
      "New Best Accuracy: (67.82%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.8114, Accuracy: 3521/7721 (45.60%)\n",
      "MY Current Accuracy: 45.60290117860381, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:14<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.1125, Accuracy: 4313/7721 (55.86%)\n",
      "New Best Accuracy: (55.86%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.3275, Accuracy: 3613/7721 (46.79%)\n",
      "MY Current Accuracy: 46.7944566765963, at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [05:02<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.7019, Accuracy: 4037/7721 (52.29%)\n",
      "New Best Accuracy: (52.29%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4351, Accuracy: 5684/7721 (73.62%)\n",
      "New Best Accuracy: (73.62%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 73.61740707162285, at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:56<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7268, Accuracy: 5302/7721 (68.67%)\n",
      "New Best Accuracy: (68.67%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4852, Accuracy: 5646/7721 (73.13%)\n",
      "New Best Accuracy: (73.13%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 73.12524284419116, at Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:23<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.8422, Accuracy: 4642/7721 (60.12%)\n",
      "New Best Accuracy: (60.12%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8956, Accuracy: 3539/7721 (45.84%)\n",
      "MY Current Accuracy: 45.83603160212408, at Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:38<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4424, Accuracy: 3708/7721 (48.02%)\n",
      "New Best Accuracy: (48.02%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 3.0661, Accuracy: 3651/7721 (47.29%)\n",
      "MY Current Accuracy: 47.28662090402798, at Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:42<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5893, Accuracy: 5239/7721 (67.85%)\n",
      "New Best Accuracy: (67.85%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.6017, Accuracy: 5429/7721 (70.31%)\n",
      "New Best Accuracy: (70.31%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 70.31472607175236, at Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:50<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6574, Accuracy: 5521/7721 (71.51%)\n",
      "New Best Accuracy: (71.51%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.5364, Accuracy: 5465/7721 (70.78%)\n",
      "MY Current Accuracy: 70.7809869187929, at Epoch: 7\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 1.5364, Accuracy: 5465/7721 (70.78%)\n",
      "Size Prev (MB): 0.844095, Size Current (MB): 0.305273, Comp Rate: 2.765049644089061 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.8031, Accuracy: 2363/4224 (55.94%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:38<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7145, Accuracy: 5201/7721 (67.36%)\n",
      "New Best Accuracy: (67.36%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.9959, Accuracy: 4224/7721 (54.71%)\n",
      "MY Current Accuracy: 54.70793938608988, at Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:23<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.4063, Accuracy: 4269/7721 (55.29%)\n",
      "New Best Accuracy: (55.29%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6873, Accuracy: 3674/7721 (47.58%)\n",
      "MY Current Accuracy: 47.5845097785261, at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:30<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4986, Accuracy: 5632/7721 (72.94%)\n",
      "New Best Accuracy: (72.94%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.8812, Accuracy: 4448/7721 (57.61%)\n",
      "MY Current Accuracy: 57.60911798989768, at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [04:36<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0218, Accuracy: 5027/7721 (65.11%)\n",
      "New Best Accuracy: (65.11%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.2651, Accuracy: 3825/7721 (49.54%)\n",
      "MY Current Accuracy: 49.540214998057245, at Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [03:58<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.7759, Accuracy: 4557/7721 (59.02%)\n",
      "New Best Accuracy: (59.02%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.3747, Accuracy: 3348/7721 (43.36%)\n",
      "MY Current Accuracy: 43.362258774770105, at Epoch: 4\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:20<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.1405, Accuracy: 3321/7721 (43.01%)\n",
      "New Best Accuracy: (43.01%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8965, Accuracy: 3629/7721 (47.00%)\n",
      "New Best Accuracy: (47.00%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 47.00168371972543, at Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:20<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5376, Accuracy: 5449/7721 (70.57%)\n",
      "New Best Accuracy: (70.57%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4141, Accuracy: 5670/7721 (73.44%)\n",
      "New Best Accuracy: (73.44%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 73.43608340888485, at Epoch: 6\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:52<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.6153, Accuracy: 3592/7721 (46.52%)\n",
      "New Best Accuracy: (46.52%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 3.8137, Accuracy: 3716/7721 (48.13%)\n",
      "New Best Accuracy: (48.13%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 48.12848076674006, at Epoch: 7\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 3.8137, Accuracy: 3716/7721 (48.13%)\n",
      "Size Prev (MB): 0.8441, Size Current (MB): 0.305273, Comp Rate: 2.765066022871331 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.1853, Accuracy: 2470/4224 (58.48%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:39<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3485, Accuracy: 4586/7721 (59.40%)\n",
      "New Best Accuracy: (59.40%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8436, Accuracy: 5251/7721 (68.01%)\n",
      "New Best Accuracy: (68.01%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 68.00932521694081, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [02:53<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7389, Accuracy: 5133/7721 (66.48%)\n",
      "New Best Accuracy: (66.48%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.5164, Accuracy: 5448/7721 (70.56%)\n",
      "New Best Accuracy: (70.56%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 70.5608081854682, at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:21<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6659, Accuracy: 4092/7721 (53.00%)\n",
      "New Best Accuracy: (53.00%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.0696, Accuracy: 3373/7721 (43.69%)\n",
      "MY Current Accuracy: 43.68605102965937, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:55<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.2389, Accuracy: 4589/7721 (59.44%)\n",
      "New Best Accuracy: (59.44%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.8661, Accuracy: 3462/7721 (44.84%)\n",
      "MY Current Accuracy: 44.83875145706515, at Epoch: 3\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:55<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8204, Accuracy: 4903/7721 (63.50%)\n",
      "New Best Accuracy: (63.50%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.3438, Accuracy: 3497/7721 (45.29%)\n",
      "MY Current Accuracy: 45.29206061391012, at Epoch: 4\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:39<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.1290, Accuracy: 3454/7721 (44.74%)\n",
      "New Best Accuracy: (44.74%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 11.4909, Accuracy: 2464/7721 (31.91%)\n",
      "MY Current Accuracy: 31.912964641885765, at Epoch: 5\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:38<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 10.7411, Accuracy: 2766/7721 (35.82%)\n",
      "New Best Accuracy: (35.82%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 16.4997, Accuracy: 1874/7721 (24.27%)\n",
      "MY Current Accuracy: 24.271467426499157, at Epoch: 6\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:39<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3307, Accuracy: 5748/7721 (74.45%)\n",
      "New Best Accuracy: (74.45%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 7.6494, Accuracy: 2422/7721 (31.37%)\n",
      "MY Current Accuracy: 31.368993653671804, at Epoch: 7\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 7.6494, Accuracy: 2422/7721 (31.37%)\n",
      "Size Prev (MB): 0.8441, Size Current (MB): 0.305271, Comp Rate: 2.7650841383557556 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 5.4624, Accuracy: 2404/4224 (56.91%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:19<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8057, Accuracy: 5225/7721 (67.67%)\n",
      "New Best Accuracy: (67.67%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6074, Accuracy: 5284/7721 (68.44%)\n",
      "New Best Accuracy: (68.44%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 68.43673099339463, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6179, Accuracy: 5567/7721 (72.10%)\n",
      "New Best Accuracy: (72.10%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5009, Accuracy: 5555/7721 (71.95%)\n",
      "MY Current Accuracy: 71.94663903639425, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0418, Accuracy: 3951/7721 (51.17%)\n",
      "New Best Accuracy: (51.17%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.9540, Accuracy: 3520/7721 (45.59%)\n",
      "MY Current Accuracy: 45.58994948840824, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.0171, Accuracy: 3707/7721 (48.01%)\n",
      "New Best Accuracy: (48.01%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6420, Accuracy: 3511/7721 (45.47%)\n",
      "MY Current Accuracy: 45.473384276648105, at Epoch: 3\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.0433, Accuracy: 3664/7721 (47.45%)\n",
      "New Best Accuracy: (47.45%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0271, Accuracy: 4351/7721 (56.35%)\n",
      "New Best Accuracy: (56.35%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 56.35280404092734, at Epoch: 4\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:51<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.5730, Accuracy: 3429/7721 (44.41%)\n",
      "New Best Accuracy: (44.41%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3274, Accuracy: 3853/7721 (49.90%)\n",
      "New Best Accuracy: (49.90%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 49.90286232353322, at Epoch: 5\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:51<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.5229, Accuracy: 3250/7721 (42.09%)\n",
      "New Best Accuracy: (42.09%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.7739, Accuracy: 3133/7721 (40.58%)\n",
      "MY Current Accuracy: 40.577645382722444, at Epoch: 6\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:51<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.8601, Accuracy: 3237/7721 (41.92%)\n",
      "New Best Accuracy: (41.92%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 4.1034, Accuracy: 3173/7721 (41.10%)\n",
      "MY Current Accuracy: 41.095712990545266, at Epoch: 7\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 4.1034, Accuracy: 3173/7721 (41.10%)\n",
      "Size Prev (MB): 0.8441, Size Current (MB): 0.305269, Comp Rate: 2.765102254077551 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.7984, Accuracy: 2050/4224 (48.53%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:14<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9992, Accuracy: 4692/7721 (60.77%)\n",
      "New Best Accuracy: (60.77%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.0522, Accuracy: 3480/7721 (45.07%)\n",
      "MY Current Accuracy: 45.071881880585416, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:19<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 5171/7721 (66.97%)\n",
      "New Best Accuracy: (66.97%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.4595, Accuracy: 3439/7721 (44.54%)\n",
      "MY Current Accuracy: 44.54086258256702, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:19<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9552, Accuracy: 5045/7721 (65.34%)\n",
      "New Best Accuracy: (65.34%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.0503, Accuracy: 3860/7721 (49.99%)\n",
      "MY Current Accuracy: 49.99352415490222, at Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:19<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7240, Accuracy: 5063/7721 (65.57%)\n",
      "New Best Accuracy: (65.57%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2803, Accuracy: 3875/7721 (50.19%)\n",
      "MY Current Accuracy: 50.18779950783577, at Epoch: 3\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9316, Accuracy: 4475/7721 (57.96%)\n",
      "New Best Accuracy: (57.96%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8872, Accuracy: 4254/7721 (55.10%)\n",
      "MY Current Accuracy: 55.096490091957, at Epoch: 4\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:52<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.0933, Accuracy: 3657/7721 (47.36%)\n",
      "New Best Accuracy: (47.36%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 15.7059, Accuracy: 2325/7721 (30.11%)\n",
      "MY Current Accuracy: 30.112679704701463, at Epoch: 5\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:51<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.4340, Accuracy: 3416/7721 (44.24%)\n",
      "New Best Accuracy: (44.24%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.7948, Accuracy: 3186/7721 (41.26%)\n",
      "MY Current Accuracy: 41.26408496308768, at Epoch: 6\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:52<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3505, Accuracy: 5726/7721 (74.16%)\n",
      "New Best Accuracy: (74.16%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4017, Accuracy: 5566/7721 (72.09%)\n",
      "MY Current Accuracy: 72.08910762854552, at Epoch: 7\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 1.4017, Accuracy: 5566/7721 (72.09%)\n",
      "Size Prev (MB): 0.844102, Size Current (MB): 0.305275, Comp Rate: 2.765054459094259 \n",
      "[[47.72727273 70.78098692  2.76504964]\n",
      " [55.94223485 48.12848077  2.76506602]\n",
      " [58.47537879 31.36899365  2.76508414]\n",
      " [56.91287879 41.09571299  2.76510225]\n",
      " [48.53219697 72.08910763  2.76505446]]\n",
      "Accuracy: 52.6926563916591, Acc_Std: 16.207587172623345, Comp Rate Avg.: 2.7650713036975914, Comp Rate Std.: 1.951112963898013e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5208, Accuracy: 5236/7721 (67.82%)\n",
      "New Best Accuracy: (67.82%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2318, Accuracy: 3783/7721 (49.00%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8106, Accuracy: 4912/7721 (63.62%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9159, Accuracy: 4534/7721 (58.72%)\n",
      "MY Current Accuracy: 58.722963346716746, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8759, Accuracy: 4901/7721 (63.48%)\n",
      "New Best Accuracy: (63.48%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3787, Accuracy: 4444/7721 (57.56%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5413, Accuracy: 5636/7721 (73.00%)\n",
      "New Best Accuracy: (73.00%) at Epoch: (3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4831, Accuracy: 5708/7721 (73.93%)\n",
      "New Best Accuracy: (73.93%) at Epoch: (3)\n",
      "\n",
      "MY Current Accuracy: 73.92824763631654, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:57<00:00,  8.02it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8984, Accuracy: 5145/7721 (66.64%)\n",
      "New Best Accuracy: (66.64%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:15<00:00,  6.16it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1443, Accuracy: 4993/7721 (64.67%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4658, Accuracy: 5278/7721 (68.36%)\n",
      "New Best Accuracy: (68.36%) at Epoch: (3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7637, Accuracy: 5052/7721 (65.43%)\n",
      "MY Current Accuracy: 65.43193886802227, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.76it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2018, Accuracy: 4009/7721 (51.92%)\n",
      "New Best Accuracy: (51.92%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6813, Accuracy: 4908/7721 (63.57%)\n",
      "New Best Accuracy: (63.57%) at Epoch: (2)\n",
      "\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7062, Accuracy: 5157/7721 (66.79%)\n",
      "New Best Accuracy: (66.79%) at Epoch: (3)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.9336, Accuracy: 3253/7721 (42.13%)\n",
      "MY Current Accuracy: 42.13184820619091, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 2.9336, Accuracy: 3253/7721 (42.13%)\n",
      "Size Prev (MB): 0.844102, Size Current (MB): 0.305273, Comp Rate: 2.7650725743842397 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.8031, Accuracy: 2363/4224 (55.94%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7145, Accuracy: 5201/7721 (67.36%)\n",
      "New Best Accuracy: (67.36%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6251, Accuracy: 5192/7721 (67.25%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2152, Accuracy: 4251/7721 (55.06%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.5070, Accuracy: 3539/7721 (45.84%)\n",
      "MY Current Accuracy: 45.83603160212408, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:06<00:00,  6.99it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3722, Accuracy: 5581/7721 (72.28%)\n",
      "New Best Accuracy: (72.28%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.5611, Accuracy: 4342/7721 (56.24%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0533, Accuracy: 4909/7721 (63.58%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6.4043, Accuracy: 3007/7721 (38.95%)\n",
      "MY Current Accuracy: 38.94573241808056, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.76it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.4140, Accuracy: 4985/7721 (64.56%)\n",
      "New Best Accuracy: (64.56%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5060, Accuracy: 5617/7721 (72.75%)\n",
      "New Best Accuracy: (72.75%) at Epoch: (2)\n",
      "\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9494, Accuracy: 4900/7721 (63.46%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.3257, Accuracy: 3644/7721 (47.20%)\n",
      "MY Current Accuracy: 47.19595907265898, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5765, Accuracy: 5496/7721 (71.18%)\n",
      "New Best Accuracy: (71.18%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.75it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6175, Accuracy: 4901/7721 (63.48%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.5260, Accuracy: 4615/7721 (59.77%)\n",
      "\n",
      "Test set: Average loss: 2.1889, Accuracy: 3945/7721 (51.09%)\n",
      "MY Current Accuracy: 51.09441782152571, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 2.1889, Accuracy: 3945/7721 (51.09%)\n",
      "Size Prev (MB): 0.844102, Size Current (MB): 0.305271, Comp Rate: 2.765090689911587 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.1853, Accuracy: 2470/4224 (58.48%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:06<00:00,  6.98it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3485, Accuracy: 4586/7721 (59.40%)\n",
      "New Best Accuracy: (59.40%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2408, Accuracy: 4171/7721 (54.02%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0209, Accuracy: 4596/7721 (59.53%)\n",
      "New Best Accuracy: (59.53%) at Epoch: (3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.6164, Accuracy: 3383/7721 (43.82%)\n",
      "MY Current Accuracy: 43.81556793161508, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6944, Accuracy: 5121/7721 (66.33%)\n",
      "New Best Accuracy: (66.33%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3683, Accuracy: 4987/7721 (64.59%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6092, Accuracy: 5214/7721 (67.53%)\n",
      "New Best Accuracy: (67.53%) at Epoch: (3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4536, Accuracy: 5714/7721 (74.01%)\n",
      "New Best Accuracy: (74.01%) at Epoch: (3)\n",
      "\n",
      "MY Current Accuracy: 74.00595777748997, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9232, Accuracy: 4641/7721 (60.11%)\n",
      "New Best Accuracy: (60.11%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.7070, Accuracy: 4551/7721 (58.94%)\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5956, Accuracy: 5180/7721 (67.09%)\n",
      "New Best Accuracy: (67.09%) at Epoch: (3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6663, Accuracy: 3580/7721 (46.37%)\n",
      "MY Current Accuracy: 46.367050900142466, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:09<00:00,  6.68it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1190, Accuracy: 4978/7721 (64.47%)\n",
      "New Best Accuracy: (64.47%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:18<00:00,  5.96it/s]\n",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1783, Accuracy: 5053/7721 (65.44%)\n",
      "New Best Accuracy: (65.44%) at Epoch: (2)\n",
      "\n",
      "Epoch:     3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5583, Accuracy: 5617/7721 (72.75%)\n",
      "New Best Accuracy: (72.75%) at Epoch: (3)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.0125, Accuracy: 4396/7721 (56.94%)\n",
      "MY Current Accuracy: 56.935630099728016, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 2.0125, Accuracy: 4396/7721 (56.94%)\n",
      "Size Prev (MB): 0.844102, Size Current (MB): 0.305267, Comp Rate: 2.7651269216783994 \n",
      "[[47.72727273 42.13184821  2.76507257]\n",
      " [55.94223485 51.09441782  2.76509069]\n",
      " [58.47537879 56.9356301   2.76512692]]\n",
      "Accuracy: 50.053965375814876, Acc_Std: 6.088234311998486, Comp Rate Avg.: 2.7650967286580754, Comp Rate Std.: 2.2594349440853163e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.2083, Accuracy: 1295/1408 (91.97%)\n",
      "\n",
      "Test set: Average loss: 1.4236, Accuracy: 5497/7721 (71.20%)\n",
      "New Best Accuracy: (71.20%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.8486, Accuracy: 3490/7721 (45.20%)\n",
      "MY Current Accuracy: 45.20139878254112, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1700, Accuracy: 1311/1408 (93.11%)\n",
      "\n",
      "Test set: Average loss: 1.7953, Accuracy: 4783/7721 (61.95%)\n",
      "New Best Accuracy: (61.95%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.4838, Accuracy: 3706/7721 (48.00%)\n",
      "MY Current Accuracy: 47.99896386478436, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.1150, Accuracy: 987/1408 (70.10%)\n",
      "\n",
      "Test set: Average loss: 2.9515, Accuracy: 3628/7721 (46.99%)\n",
      "New Best Accuracy: (46.99%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.1408, Accuracy: 3342/7721 (43.28%)\n",
      "MY Current Accuracy: 43.284548633596685, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0551, Accuracy: 1383/1408 (98.22%)\n",
      "\n",
      "Test set: Average loss: 1.5361, Accuracy: 5652/7721 (73.20%)\n",
      "New Best Accuracy: (73.20%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.3454, Accuracy: 5775/7721 (74.80%)\n",
      "New Best Accuracy: (74.80%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 74.79601087941977, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 1.3454, Accuracy: 5775/7721 (74.80%)\n",
      "Size Prev (MB): 0.844102, Size Current (MB): 0.305271, Comp Rate: 2.765090689911587 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.8031, Accuracy: 2363/4224 (55.94%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:07<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0879, Accuracy: 1365/1408 (96.95%)\n",
      "\n",
      "Test set: Average loss: 1.5877, Accuracy: 5559/7721 (72.00%)\n",
      "New Best Accuracy: (72.00%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9119, Accuracy: 4395/7721 (56.92%)\n",
      "MY Current Accuracy: 56.922678409532445, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.2351, Accuracy: 950/1408 (67.47%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6639, Accuracy: 4643/7721 (60.13%)\n",
      "New Best Accuracy: (60.13%) at Epoch: (1)\n",
      "\n",
      "Epoch:     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1463, Accuracy: 1339/1408 (95.10%)\n",
      "\n",
      "Test set: Average loss: 1.7396, Accuracy: 5006/7721 (64.84%)\n",
      "New Best Accuracy: (64.84%) at Epoch: (2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.6643, Accuracy: 3583/7721 (46.41%)\n",
      "MY Current Accuracy: 46.40590597072918, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0817, Accuracy: 1364/1408 (96.88%)\n",
      "\n",
      "Test set: Average loss: 1.6083, Accuracy: 5303/7721 (68.68%)\n",
      "New Best Accuracy: (68.68%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9298, Accuracy: 4775/7721 (61.84%)\n",
      "MY Current Accuracy: 61.84432068384924, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1387, Accuracy: 1342/1408 (95.31%)\n",
      "\n",
      "Test set: Average loss: 3.2980, Accuracy: 4195/7721 (54.33%)\n",
      "New Best Accuracy: (54.33%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7732, Accuracy: 3709/7721 (48.04%)\n",
      "MY Current Accuracy: 48.037818935371064, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 2.7732, Accuracy: 3709/7721 (48.04%)\n",
      "Size Prev (MB): 0.8441, Size Current (MB): 0.305273, Comp Rate: 2.765066022871331 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 3.1853, Accuracy: 2470/4224 (58.48%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:19<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0520, Accuracy: 992/1408 (70.45%)\n",
      "\n",
      "Test set: Average loss: 2.6487, Accuracy: 4634/7721 (60.02%)\n",
      "New Best Accuracy: (60.02%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8462, Accuracy: 5166/7721 (66.91%)\n",
      "New Best Accuracy: (66.91%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.90843155031732, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.6799, Accuracy: 1229/1408 (87.29%)\n",
      "\n",
      "Test set: Average loss: 2.0492, Accuracy: 4385/7721 (56.79%)\n",
      "New Best Accuracy: (56.79%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9003, Accuracy: 4376/7721 (56.68%)\n",
      "MY Current Accuracy: 56.6765962958166, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1298, Accuracy: 1357/1408 (96.38%)\n",
      "\n",
      "Test set: Average loss: 1.5606, Accuracy: 5524/7721 (71.55%)\n",
      "New Best Accuracy: (71.55%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6490, Accuracy: 5464/7721 (70.77%)\n",
      "MY Current Accuracy: 70.76803522859733, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:14<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1061, Accuracy: 1362/1408 (96.73%)\n",
      "\n",
      "Test set: Average loss: 1.7238, Accuracy: 4747/7721 (61.48%)\n",
      "New Best Accuracy: (61.48%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Test set: Average loss: 3.7843, Accuracy: 3394/7721 (43.96%)\n",
      "MY Current Accuracy: 43.95803652376635, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Test set: Average loss: 3.7843, Accuracy: 3394/7721 (43.96%)\n",
      "Size Prev (MB): 0.844096, Size Current (MB): 0.305265, Comp Rate: 2.7651253828640687 \n",
      "[[47.72727273 74.79601088  2.76509069]\n",
      " [55.94223485 48.03781894  2.76506602]\n",
      " [58.47537879 43.95803652  2.76512538]]\n",
      "Accuracy: 55.59728877951906, Acc_Std: 13.677337797330336, Comp Rate Avg.: 2.7650940318823287, Comp Rate Std.: 2.434856273354587e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:09<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.2083, Accuracy: 1295/1408 (91.97%)\n",
      "\n",
      "Train or Test set: Average loss: 1.4236, Accuracy: 5497/7721 (71.20%)\n",
      "New Best Accuracy: (71.20%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 2.8486, Accuracy: 3490/7721 (45.20%)\n",
      "MY Current Accuracy: 45.20139878254112, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:10<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1700, Accuracy: 1311/1408 (93.11%)\n",
      "\n",
      "Train or Test set: Average loss: 1.7953, Accuracy: 4783/7721 (61.95%)\n",
      "New Best Accuracy: (61.95%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 3.4838, Accuracy: 3706/7721 (48.00%)\n",
      "MY Current Accuracy: 47.99896386478436, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:10<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.1150, Accuracy: 987/1408 (70.10%)\n",
      "\n",
      "Train or Test set: Average loss: 2.9515, Accuracy: 3628/7721 (46.99%)\n",
      "New Best Accuracy: (46.99%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.1408, Accuracy: 3342/7721 (43.28%)\n",
      "MY Current Accuracy: 43.284548633596685, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 169/465 [00:24<00:49,  5.93it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-14628e92d355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetResult4qaQuantChannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhhar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader_hhar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader_hhar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-85368cf3be0d>\u001b[0m in \u001b[0;36mgetResult4qaQuantChannel\u001b[0;34m(args, rModel, train_loader, test_loader, num_calibration_batches, num_eval_batches)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqaQuantizePerChannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_calibration_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_eval_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mret_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mret_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-85368cf3be0d>\u001b[0m in \u001b[0;36mqaQuantizePerChannel\u001b[0;34m(args, rModel, train_loader, test_loader, num_calibration_batches, num_eval_batches)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-85368cf3be0d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, test_loader, optimizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularized_nll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4a7ed748c18b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdequant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/ydk21/projects/tinyML/yono/yono/src/models/dscnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorchcv/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdw_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpw_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorchcv/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 self._forward_hooks.values()):\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36m_observer_forward_hook\u001b[0;34m(self, input, output)\u001b[0m\n\u001b[1;32m     80\u001b[0m     r\"\"\"Forward hook that calls observer on the output\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_post_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_observer_forward_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/quantization/fake_quantize.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserver_enabled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_post_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0m_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_zero_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_qparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0m_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_zero_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_zero_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/quantization/fake_quantize.py\u001b[0m in \u001b[0;36mcalculate_qparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_qparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_post_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_qparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/quantization/observer.py\u001b[0m in \u001b[0;36mcalculate_qparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_qparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;34mr\"\"\"Calculates the quantization parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_qparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/quantization/observer.py\u001b[0m in \u001b[0;36m_calculate_qparams\u001b[0;34m(self, min_val, max_val)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmin_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 warnings.warn(\n\u001b[1;32m    242\u001b[0m                     \u001b[0;31m\"\u001b[0m\u001b[0mmust\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mobserver\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mcalculate_qparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:55<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0500, Accuracy: 1379/1408 (97.94%)\n",
      "\n",
      "Train or Test set: Average loss: 1.7899, Accuracy: 4919/7721 (63.71%)\n",
      "New Best Accuracy: (63.71%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.7755, Accuracy: 5013/7721 (64.93%)\n",
      "New Best Accuracy: (64.93%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 64.92682295039502, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:07<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1450, Accuracy: 1316/1408 (93.47%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2874, Accuracy: 5632/7721 (72.94%)\n",
      "New Best Accuracy: (72.94%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.8329, Accuracy: 3773/7721 (48.87%)\n",
      "MY Current Accuracy: 48.86672710788758, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:07<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0328, Accuracy: 1391/1408 (98.79%)\n",
      "\n",
      "Train or Test set: Average loss: 1.1660, Accuracy: 5759/7721 (74.59%)\n",
      "New Best Accuracy: (74.59%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.3877, Accuracy: 5606/7721 (72.61%)\n",
      "MY Current Accuracy: 72.60717523636835, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:10<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.4102, Accuracy: 1210/1408 (85.94%)\n",
      "\n",
      "Train or Test set: Average loss: 4.0691, Accuracy: 3663/7721 (47.44%)\n",
      "New Best Accuracy: (47.44%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Train or Test set: Average loss: 2.5107, Accuracy: 4001/7721 (51.82%)\n",
      "New Best Accuracy: (51.82%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 51.81971247247766, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 2.5107, Accuracy: 4001/7721 (51.82%)\n",
      "Size Prev (MB): 0.843981, Size Current (MB): 0.305149, Comp Rate: 2.7657996585274733 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.8031, Accuracy: 2363/4224 (55.94%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:57<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.2364, Accuracy: 1270/1408 (90.20%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6251, Accuracy: 5347/7721 (69.25%)\n",
      "New Best Accuracy: (69.25%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.6458, Accuracy: 5161/7721 (66.84%)\n",
      "MY Current Accuracy: 66.84367309933947, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:20<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0429, Accuracy: 1388/1408 (98.58%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6622, Accuracy: 5137/7721 (66.53%)\n",
      "New Best Accuracy: (66.53%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.7664, Accuracy: 5004/7721 (64.81%)\n",
      "MY Current Accuracy: 64.81025773863489, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:12<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0556, Accuracy: 1383/1408 (98.22%)\n",
      "\n",
      "Train or Test set: Average loss: 1.4344, Accuracy: 5131/7721 (66.46%)\n",
      "New Best Accuracy: (66.46%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.4650, Accuracy: 5352/7721 (69.32%)\n",
      "New Best Accuracy: (69.32%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 69.31744592669344, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [00:52<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0431, Accuracy: 1385/1408 (98.37%)\n",
      "\n",
      "Train or Test set: Average loss: 1.1791, Accuracy: 5345/7721 (69.23%)\n",
      "New Best Accuracy: (69.23%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Train or Test set: Average loss: 1.1185, Accuracy: 6162/7721 (79.81%)\n",
      "New Best Accuracy: (79.81%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 79.80831498510555, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.1185, Accuracy: 6162/7721 (79.81%)\n",
      "Size Prev (MB): 0.844018, Size Current (MB): 0.305176, Comp Rate: 2.7656761999633 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 3.1853, Accuracy: 2470/4224 (58.48%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:32<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0471, Accuracy: 1386/1408 (98.44%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2583, Accuracy: 5794/7721 (75.04%)\n",
      "New Best Accuracy: (75.04%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Train or Test set: Average loss: 1.3130, Accuracy: 5978/7721 (77.43%)\n",
      "New Best Accuracy: (77.43%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 77.42520398912058, at Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0565, Accuracy: 1376/1408 (97.73%)\n",
      "\n",
      "Train or Test set: Average loss: 1.4564, Accuracy: 5606/7721 (72.61%)\n",
      "New Best Accuracy: (72.61%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.4238, Accuracy: 5810/7721 (75.25%)\n",
      "New Best Accuracy: (75.25%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 75.24932003626473, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0313, Accuracy: 1395/1408 (99.08%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2592, Accuracy: 5885/7721 (76.22%)\n",
      "New Best Accuracy: (76.22%) at Epoch: (1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.3169, Accuracy: 5827/7721 (75.47%)\n",
      "MY Current Accuracy: 75.46949876958944, at Epoch: 2\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:26<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0292, Accuracy: 1394/1408 (99.01%)\n",
      "\n",
      "Train or Test set: Average loss: 1.3403, Accuracy: 5472/7721 (70.87%)\n",
      "New Best Accuracy: (70.87%) at Epoch: (1)\n",
      "\n",
      "\n",
      "Train or Test set: Average loss: 1.3377, Accuracy: 5573/7721 (72.18%)\n",
      "New Best Accuracy: (72.18%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 72.17976945991452, at Epoch: 3\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.3377, Accuracy: 5573/7721 (72.18%)\n",
      "Size Prev (MB): 0.844015, Size Current (MB): 0.305164, Comp Rate: 2.7657751241955144 \n",
      "[[47.72727273 51.81971247  2.76579966]\n",
      " [55.94223485 79.80831499  2.7656762 ]\n",
      " [58.47537879 72.17976946  2.76577512]]\n",
      "Accuracy: 67.93593230583258, Acc_Std: 11.813779609570197, Comp Rate Avg.: 2.765750327562096, Comp Rate Std.: 5.33645265358415e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 6.9558, Accuracy: 2016/4224 (47.73%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:35<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0417, Accuracy: 501/512 (97.85%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5830, Accuracy: 2436/4000 (60.90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.7525, Accuracy: 5170/7721 (66.96%)\n",
      "New Best Accuracy: (66.96%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.9602383110996, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:33<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0190, Accuracy: 508/512 (99.22%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2061, Accuracy: 3013/4000 (75.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.1549, Accuracy: 5228/7721 (67.71%)\n",
      "New Best Accuracy: (67.71%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.7114363424427, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:39<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0293, Accuracy: 508/512 (99.22%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5481, Accuracy: 2481/4000 (62.02%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5657, Accuracy: 5138/7721 (66.55%)\n",
      "New Best Accuracy: (66.55%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.54578422484134, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.5657, Accuracy: 5138/7721 (66.55%)\n",
      "Size Prev (MB): 0.844012, Size Current (MB): 0.305169, Comp Rate: 2.7657199781104893 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.8031, Accuracy: 2363/4224 (55.94%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:35<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1770, Accuracy: 480/512 (93.75%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6360, Accuracy: 2747/4000 (68.67%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 6.9069, Accuracy: 3110/7721 (40.28%)\n",
      "New Best Accuracy: (40.28%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 40.279756508224324, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0791, Accuracy: 498/512 (97.27%)\n",
      "\n",
      "Train or Test set: Average loss: 2.0740, Accuracy: 2423/4000 (60.58%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5529, Accuracy: 5135/7721 (66.51%)\n",
      "New Best Accuracy: (66.51%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.50692915425464, at Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:26<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0415, Accuracy: 508/512 (99.22%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2044, Accuracy: 2762/4000 (69.05%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2401, Accuracy: 5904/7721 (76.47%)\n",
      "New Best Accuracy: (76.47%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 76.46677891464836, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.2401, Accuracy: 5904/7721 (76.47%)\n",
      "Size Prev (MB): 0.844019, Size Current (MB): 0.305175, Comp Rate: 2.7656885393626607 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 3.1853, Accuracy: 2470/4224 (58.48%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0423, Accuracy: 501/512 (97.85%)\n",
      "\n",
      "Train or Test set: Average loss: 1.3194, Accuracy: 2967/4000 (74.17%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.2491, Accuracy: 6044/7721 (78.28%)\n",
      "New Best Accuracy: (78.28%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 78.28001554202824, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0245, Accuracy: 507/512 (99.02%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5458, Accuracy: 2566/4000 (64.15%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.4327, Accuracy: 5427/7721 (70.29%)\n",
      "New Best Accuracy: (70.29%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 70.28882269136122, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:35<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0771, Accuracy: 500/512 (97.66%)\n",
      "\n",
      "Train or Test set: Average loss: 1.8939, Accuracy: 2738/4000 (68.45%)\n",
      "\n",
      "Train or Test set: Average loss: 2.0149, Accuracy: 5175/7721 (67.02%)\n",
      "New Best Accuracy: (67.02%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.02499676207745, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 2.0149, Accuracy: 5175/7721 (67.02%)\n",
      "Size Prev (MB): 0.844016, Size Current (MB): 0.305178, Comp Rate: 2.765651521407179 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 5.4624, Accuracy: 2404/4224 (56.91%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:30<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0612, Accuracy: 502/512 (98.05%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6781, Accuracy: 2660/4000 (66.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.4840, Accuracy: 5695/7721 (73.76%)\n",
      "New Best Accuracy: (73.76%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 73.75987566377412, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:40<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0342, Accuracy: 507/512 (99.02%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2708, Accuracy: 2946/4000 (73.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.2514, Accuracy: 5840/7721 (75.64%)\n",
      "New Best Accuracy: (75.64%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 75.63787074213185, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0448, Accuracy: 503/512 (98.24%)\n",
      "\n",
      "Train or Test set: Average loss: 1.8443, Accuracy: 2584/4000 (64.60%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6314, Accuracy: 5372/7721 (69.58%)\n",
      "New Best Accuracy: (69.58%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 69.57647973060485, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.6314, Accuracy: 5372/7721 (69.58%)\n",
      "Size Prev (MB): 0.844014, Size Current (MB): 0.305172, Comp Rate: 2.7656993433211436 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 4.7984, Accuracy: 2050/4224 (48.53%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:34<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.1767, Accuracy: 478/512 (93.36%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6463, Accuracy: 2497/4000 (62.42%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.4216, Accuracy: 5144/7721 (66.62%)\n",
      "New Best Accuracy: (66.62%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.62349436601477, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:40<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0352, Accuracy: 506/512 (98.83%)\n",
      "\n",
      "Train or Test set: Average loss: 3.4808, Accuracy: 2541/4000 (63.52%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 2.9405, Accuracy: 5071/7721 (65.68%)\n",
      "New Best Accuracy: (65.68%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 65.67802098173811, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 465/465 [01:54<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.0357, Accuracy: 506/512 (98.83%)\n",
      "\n",
      "Train or Test set: Average loss: 1.5784, Accuracy: 2487/4000 (62.17%)\n",
      "\n",
      "Train or Test set: Average loss: 1.6792, Accuracy: 5114/7721 (66.23%)\n",
      "New Best Accuracy: (66.23%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.23494366014765, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.6792, Accuracy: 5114/7721 (66.23%)\n",
      "Size Prev (MB): 0.844015, Size Current (MB): 0.305173, Comp Rate: 2.7656935574248047 \n",
      "[[47.72727273 66.54578422  2.76571998]\n",
      " [55.94223485 76.46677891  2.76568854]\n",
      " [58.47537879 67.02499676  2.76565152]\n",
      " [56.91287879 69.57647973  2.76569934]\n",
      " [48.53219697 66.23494366  2.76569356]]\n",
      "Accuracy: 69.16979665846392, Acc_Std: 3.8343268284617533, Comp Rate Avg.: 2.7656905879252554, Comp Rate Std.: 2.226947379776514e-05\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,hhar,train_loader_hhar,test_loader_hhar,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.7183, Accuracy: 3135/4224 (74.22%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:14<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5002, Accuracy: 415/512 (81.05%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8617, Accuracy: 2755/4000 (68.88%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0130, Accuracy: 4285/6381 (67.15%)\n",
      "New Best Accuracy: (67.15%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.15248393668703, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:15<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5977, Accuracy: 395/512 (77.15%)\n",
      "\n",
      "Train or Test set: Average loss: 0.9208, Accuracy: 2720/4000 (68.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0615, Accuracy: 4127/6381 (64.68%)\n",
      "New Best Accuracy: (64.68%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 64.67638301206708, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:14<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5231, Accuracy: 412/512 (80.47%)\n",
      "\n",
      "Train or Test set: Average loss: 0.9534, Accuracy: 2771/4000 (69.28%)\n",
      "\n",
      "Train or Test set: Average loss: 1.1279, Accuracy: 4193/6381 (65.71%)\n",
      "New Best Accuracy: (65.71%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 65.71070365146528, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.1279, Accuracy: 4193/6381 (65.71%)\n",
      "Size Prev (MB): 0.115389, Size Current (MB): 0.045666, Comp Rate: 2.526803310997241 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5669, Accuracy: 3302/4224 (78.17%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:15<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5833, Accuracy: 392/512 (76.56%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8303, Accuracy: 2794/4000 (69.85%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0346, Accuracy: 4253/6381 (66.65%)\n",
      "New Best Accuracy: (66.65%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.6509951418273, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:13<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5676, Accuracy: 399/512 (77.93%)\n",
      "\n",
      "Train or Test set: Average loss: 0.9059, Accuracy: 2659/4000 (66.47%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.9260, Accuracy: 4342/6381 (68.05%)\n",
      "New Best Accuracy: (68.05%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 68.04576085253095, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:08<00:00, 28.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.6129, Accuracy: 402/512 (78.52%)\n",
      "\n",
      "Train or Test set: Average loss: 0.7941, Accuracy: 2848/4000 (71.20%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8672, Accuracy: 4501/6381 (70.54%)\n",
      "New Best Accuracy: (70.54%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 70.53753330199028, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8672, Accuracy: 4501/6381 (70.54%)\n",
      "Size Prev (MB): 0.115394, Size Current (MB): 0.04567, Comp Rate: 2.526691482373549 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.5633, Accuracy: 2476/4224 (58.62%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5900, Accuracy: 393/512 (76.76%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8739, Accuracy: 2825/4000 (70.62%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0267, Accuracy: 4261/6381 (66.78%)\n",
      "New Best Accuracy: (66.78%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 66.77636734054224, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5854, Accuracy: 386/512 (75.39%)\n",
      "\n",
      "Train or Test set: Average loss: 0.7471, Accuracy: 2884/4000 (72.10%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.9139, Accuracy: 4294/6381 (67.29%)\n",
      "New Best Accuracy: (67.29%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.29352766024134, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5229, Accuracy: 399/512 (77.93%)\n",
      "\n",
      "Train or Test set: Average loss: 1.0970, Accuracy: 2634/4000 (65.85%)\n",
      "\n",
      "Train or Test set: Average loss: 1.1569, Accuracy: 4059/6381 (63.61%)\n",
      "New Best Accuracy: (63.61%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 63.61071932299013, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.1569, Accuracy: 4059/6381 (63.61%)\n",
      "Size Prev (MB): 0.115399, Size Current (MB): 0.045663, Comp Rate: 2.5271883143902065 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.8718, Accuracy: 2975/4224 (70.43%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.6291, Accuracy: 395/512 (77.15%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8527, Accuracy: 2714/4000 (67.85%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 1.0075, Accuracy: 4160/6381 (65.19%)\n",
      "New Best Accuracy: (65.19%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 65.19354333176618, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5529, Accuracy: 408/512 (79.69%)\n",
      "\n",
      "Train or Test set: Average loss: 0.7602, Accuracy: 2854/4000 (71.35%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.8628, Accuracy: 4393/6381 (68.85%)\n",
      "New Best Accuracy: (68.85%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 68.84500861933866, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5719, Accuracy: 410/512 (80.08%)\n",
      "\n",
      "Train or Test set: Average loss: 1.1664, Accuracy: 2565/4000 (64.12%)\n",
      "\n",
      "Train or Test set: Average loss: 1.2597, Accuracy: 4014/6381 (62.91%)\n",
      "New Best Accuracy: (62.91%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 62.90550070521862, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 1.2597, Accuracy: 4014/6381 (62.91%)\n",
      "Size Prev (MB): 0.115398, Size Current (MB): 0.045662, Comp Rate: 2.5272217598878717 \n",
      "QConfig(activation=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=0, quant_max=255, reduce_range=True), weight=functools.partial(<class 'torch.quantization.fake_quantize.FakeQuantize'>, observer=<class 'torch.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.6032, Accuracy: 3272/4224 (77.46%)\n",
      "Post Training Quantization: Calibration done\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.6077, Accuracy: 387/512 (75.59%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8056, Accuracy: 2777/4000 (69.42%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.9792, Accuracy: 4362/6381 (68.36%)\n",
      "New Best Accuracy: (68.36%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 68.3591913493183, at Epoch: 0\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.5884, Accuracy: 376/512 (73.44%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8649, Accuracy: 2650/4000 (66.25%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/244 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.9324, Accuracy: 4325/6381 (67.78%)\n",
      "New Best Accuracy: (67.78%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.77934493026171, at Epoch: 1\n",
      "Epoch:     1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 244/244 [00:18<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train or Test set: Average loss: 0.4700, Accuracy: 417/512 (81.45%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8249, Accuracy: 2751/4000 (68.78%)\n",
      "\n",
      "Train or Test set: Average loss: 0.8633, Accuracy: 4282/6381 (67.11%)\n",
      "New Best Accuracy: (67.11%) at Epoch: (1)\n",
      "\n",
      "MY Current Accuracy: 67.10546936216893, at Epoch: 2\n",
      "Post Training Quantization: Convert done\n",
      "\n",
      "Train or Test set: Average loss: 0.8633, Accuracy: 4282/6381 (67.11%)\n",
      "Size Prev (MB): 0.115397, Size Current (MB): 0.045661, Comp Rate: 2.527255206850485 \n",
      "[[74.21875    65.71070365  2.52680331]\n",
      " [78.17234848 70.5375333   2.52669148]\n",
      " [58.61742424 63.61071932  2.52718831]\n",
      " [70.43087121 62.90550071  2.52722176]\n",
      " [77.46212121 67.10546936  2.52725521]]\n",
      "Accuracy: 65.97398526876665, Acc_Std: 2.7267624598549105, Comp Rate Avg.: 2.527032014899871, Comp Rate Std.: 0.00023601492093965604\n"
     ]
    }
   ],
   "source": [
    "getResult4qaQuantChannel(args,ninadb2,train_loader_ninadb2,test_loader_ninadb2,32,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
